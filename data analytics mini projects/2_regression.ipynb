{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1Y9nod3kSdc_tW0aTKtzYloyOvIW8-8Rd","timestamp":1663105700221}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"pycharm":{"stem_cell":{"cell_type":"raw","source":[],"metadata":{"collapsed":false}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"9_1GISKe768k"},"source":["<center>\n","    <h3>University of Toronto</h3>\n","    <h3>Department of Mechanical and Industrial Engineering</h3>\n","    <h3>MIE368 Analytics in Action </h3>\n","    <h3>(Fall 2022)</h3>\n","    <hr>\n","    <h1>Lab 2: Linear and Logistic Regression</h1>\n","    <h3>September 21, 2022</h3>\n","</center>\n"]},{"cell_type":"markdown","metadata":{"id":"soIx6yNt8SBd"},"source":[" # Introduction\n","\n","Linear and logistic regression are two of the most widely used methods in analytics. They are used to model the relationship between a _target_ variable (i.e., dependent variable) and one or more _features_ (i.e., independent variables). The application of these methods typically falls into one of two categories based on the end goal:\n","\n"," 1. __Prediction:__ estimate the target based on given features. The goal is to obtain a model that performs well on out-of-sample data (i.e., data it hasn't seen before).\n","\n"," 2. __Inference or Information extraction:__ reveal how the target is associated with the feature variables. Care is needed with respect to model assumptions when seeking to extract information.\n","\n","__By the end of this lab you will be able to:__\n","> i) Apply linear regression to *extract information* from a continuous target.  \n","> ii) Apply logistic regression to *predict* a binary target.  \n","> iii) Apply feature selection and regularization to construct better models.  \n","> iv) Evaluate model fitness using $R^2$, mean accuracy, precision-recall, confusion matrices, and ROC curves.\n","\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"2BgKbVT1UNzF"},"source":["# Application\n","\n","In this lab, we will use data from the National Basketball League (NBA). We have two goals: (1) to understand the relationship between stats and total number of wins within a season, and (2) to predict the relationship between stats and whether a team will make the playoffs the following year. \n","Our data includes team data from all NBA seasons between 1980 and 2016 except for the two lockout seasons (1999 and 2012). For a brief introduction to basketball, please watch the first 95 seconds of the following video:\n","\n","<a href=\"https://www.youtube.com/watch?v=wYjp2zoqQrs\n","\" target=\"\"><img src=\"http://img.youtube.com/vi/wYjp2zoqQrs/0.jpg\" \n","alt=\"\" width=\"240\" height=\"180\" border=\"10\" /></a>"]},{"cell_type":"markdown","metadata":{"id":"9J-sgWRLxLwW"},"source":["## Imports and Data\n","\n","Lets start by importing the packages and data involved in this lab. "]},{"cell_type":"code","metadata":{"id":"ZJtPfP8A8O24","pycharm":{"is_executing":false},"colab":{"base_uri":"https://localhost:8080/","height":294},"executionInfo":{"status":"ok","timestamp":1664125074826,"user_tz":240,"elapsed":2772,"user":{"displayName":"Zhuolun Du","userId":"16686697190012944947"}},"outputId":"5dc1c043-591d-404c-fc7a-ec84c2a7bfd8"},"source":["# Import the packages for this lab\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","\n","# Import linear regression models\n","from sklearn.linear_model import LinearRegression, LassoCV, RidgeCV\n","\n","# Import logistic regression models\n","from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n","\n","# Import confusion matrix function from sklearn\n","from sklearn.metrics import confusion_matrix\n","\n","# Load all the data required for this lab\n","df = pd.read_csv('https://docs.google.com/uc?export=download&id=1qCI6BGZpgenI0lLcBuJHTEst5PTIqXov')\n","df.head()  # Visualize small portion of the data"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   SeasonEnd                 Team   W   PTS  oppPTS    FG   FGA    2P   2PA  \\\n","0       2014   Philadelphia 76ers  19  8155    9012  3108  7150  2531  5303   \n","1       2004      Detroit Pistons  54  7388    6909  2747  6314  2414  5346   \n","2       2004    San Antonio Spurs  57  7501    6909  2842  6434  2434  5294   \n","3       2004       Indiana Pacers  61  7493    7021  2753  6322  2304  5041   \n","4       1997  Cleveland Cavaliers  42  7173    7022  2704  5972  2221  4688   \n","\n","    3P  ...    FT   FTA   ORB   DRB   AST  STL  BLK   TOV  Conference  \\\n","0  577  ...  1362  1918   949  2556  1791  765  330  1384           0   \n","1  333  ...  1561  2074  1014  2492  1702  659  570  1241           0   \n","2  408  ...  1409  2069  1029  2669  1676  661  537  1203           1   \n","3  449  ...  1538  2014   965  2452  1774  726  411  1182           0   \n","4  483  ...  1282  1773   909  2159  1714  655  315  1188           0   \n","\n","   Playoffs  \n","0         0  \n","1         1  \n","2         1  \n","3         1  \n","4         0  \n","\n","[5 rows x 21 columns]"],"text/html":["\n","  <div id=\"df-64a20775-4540-47e0-a279-5c71f5315dd8\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>SeasonEnd</th>\n","      <th>Team</th>\n","      <th>W</th>\n","      <th>PTS</th>\n","      <th>oppPTS</th>\n","      <th>FG</th>\n","      <th>FGA</th>\n","      <th>2P</th>\n","      <th>2PA</th>\n","      <th>3P</th>\n","      <th>...</th>\n","      <th>FT</th>\n","      <th>FTA</th>\n","      <th>ORB</th>\n","      <th>DRB</th>\n","      <th>AST</th>\n","      <th>STL</th>\n","      <th>BLK</th>\n","      <th>TOV</th>\n","      <th>Conference</th>\n","      <th>Playoffs</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2014</td>\n","      <td>Philadelphia 76ers</td>\n","      <td>19</td>\n","      <td>8155</td>\n","      <td>9012</td>\n","      <td>3108</td>\n","      <td>7150</td>\n","      <td>2531</td>\n","      <td>5303</td>\n","      <td>577</td>\n","      <td>...</td>\n","      <td>1362</td>\n","      <td>1918</td>\n","      <td>949</td>\n","      <td>2556</td>\n","      <td>1791</td>\n","      <td>765</td>\n","      <td>330</td>\n","      <td>1384</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2004</td>\n","      <td>Detroit Pistons</td>\n","      <td>54</td>\n","      <td>7388</td>\n","      <td>6909</td>\n","      <td>2747</td>\n","      <td>6314</td>\n","      <td>2414</td>\n","      <td>5346</td>\n","      <td>333</td>\n","      <td>...</td>\n","      <td>1561</td>\n","      <td>2074</td>\n","      <td>1014</td>\n","      <td>2492</td>\n","      <td>1702</td>\n","      <td>659</td>\n","      <td>570</td>\n","      <td>1241</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2004</td>\n","      <td>San Antonio Spurs</td>\n","      <td>57</td>\n","      <td>7501</td>\n","      <td>6909</td>\n","      <td>2842</td>\n","      <td>6434</td>\n","      <td>2434</td>\n","      <td>5294</td>\n","      <td>408</td>\n","      <td>...</td>\n","      <td>1409</td>\n","      <td>2069</td>\n","      <td>1029</td>\n","      <td>2669</td>\n","      <td>1676</td>\n","      <td>661</td>\n","      <td>537</td>\n","      <td>1203</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2004</td>\n","      <td>Indiana Pacers</td>\n","      <td>61</td>\n","      <td>7493</td>\n","      <td>7021</td>\n","      <td>2753</td>\n","      <td>6322</td>\n","      <td>2304</td>\n","      <td>5041</td>\n","      <td>449</td>\n","      <td>...</td>\n","      <td>1538</td>\n","      <td>2014</td>\n","      <td>965</td>\n","      <td>2452</td>\n","      <td>1774</td>\n","      <td>726</td>\n","      <td>411</td>\n","      <td>1182</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1997</td>\n","      <td>Cleveland Cavaliers</td>\n","      <td>42</td>\n","      <td>7173</td>\n","      <td>7022</td>\n","      <td>2704</td>\n","      <td>5972</td>\n","      <td>2221</td>\n","      <td>4688</td>\n","      <td>483</td>\n","      <td>...</td>\n","      <td>1282</td>\n","      <td>1773</td>\n","      <td>909</td>\n","      <td>2159</td>\n","      <td>1714</td>\n","      <td>655</td>\n","      <td>315</td>\n","      <td>1188</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows Ã— 21 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-64a20775-4540-47e0-a279-5c71f5315dd8')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-64a20775-4540-47e0-a279-5c71f5315dd8 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-64a20775-4540-47e0-a279-5c71f5315dd8');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":1}]},{"cell_type":"markdown","metadata":{"id":"8JFxtBtoUr8r"},"source":["\n","The columns in the dataset should be as follows (21 columns total):\n","\n","* **SeasonEnd**: season of play\n","* **Team**: team name (categorical)\n","* **W**: wins\n","* **PTS**: points scored over the season\n","* **oppPTS**: points scored against the team over the season\n","* **FG**: field goals made\n","* **FGA**: field goals attempted\n","* **2P**: 2-point field goals made\n","* **2PA**: 2-point field goals attempted\n","* **3P**: 3-point field goals made\n","* **3PA**: 3-point field goals attempted\n","* **FT**: Free throws made\n","* **FTA**: Free throws attempted\n","* **ORB**: Offensive rebounds made\n","* **DRB**: Defensive rebounds made\n","* **AST**: Assists made\n","* **STL**: Steals made\n","* **BLK**: Blocks made\n","* **TOV**: Turnovers made\n","* **Conference**: NBA conference that team plays is (0 = eastern, 1 = western)\n","* **Playoffs**: Whether or not team made playoffs (0 = missed, 1 = made)\n","\n","Before we do anything, we should always try some exploratory data analysis to better understand what we are dealing with. Answer the questions below.\n","\n","### Exercise\n","\n","1. Is there any missing data?\n","2. Which team won the most games in a season?\n","3. Which team was the best defensive team (based on points scored against the team)?\n","4. Aside from playoffs, which feature is the most correlated with wins?"]},{"cell_type":"code","metadata":{"id":"wsphPBZBQ6Zd","pycharm":{"is_executing":false}},"source":["# Question 1\n","\n","# Write your code here.\n","\n","# -------------------\n","\n","\n","# -------------------"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.isna().sum().sum()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q9Is-JDaVplM","executionInfo":{"status":"ok","timestamp":1664125074827,"user_tz":240,"elapsed":17,"user":{"displayName":"Zhuolun Du","userId":"16686697190012944947"}},"outputId":"39ecb6ff-7d38-4dcd-ca72-2c4be1945ac0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"-DGdvAdGYsT-","pycharm":{"is_executing":false}},"source":["# Question 2\n","\n","# Write your code here.\n","\n","# -------------------\n","\n","\n","# -------------------"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.iloc[df['W'].idxmax()]['Team']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":37},"id":"jdjgczqgV9Sg","executionInfo":{"status":"ok","timestamp":1664125075177,"user_tz":240,"elapsed":50,"user":{"displayName":"Zhuolun Du","userId":"16686697190012944947"}},"outputId":"15b5de35-c9f2-427d-a5fc-b6975e412af5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Golden State Warriors'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"kyJefMh1Zap1"},"source":["# Question 3\n","\n","# Write your code here.\n","\n","# -------------------\n","\n","\n","# -------------------\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.iloc[df['oppPTS'].idxmin()]['Team']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":37},"id":"AbQLSswrWeWg","executionInfo":{"status":"ok","timestamp":1664125075178,"user_tz":240,"elapsed":48,"user":{"displayName":"Zhuolun Du","userId":"16686697190012944947"}},"outputId":"83508204-fd28-4602-b7a0-1bc2e150a5e8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Detroit Pistons'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"bxdpRx8oZtnt"},"source":["# Question 4\n","\n","# Write your code here.\n","\n","# -------------------\n","\n","\n","# -------------------"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.corr()['W'].drop(['W', 'Playoffs']).idxmax()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":37},"id":"LooihnvlWrv_","executionInfo":{"status":"ok","timestamp":1664125075179,"user_tz":240,"elapsed":48,"user":{"displayName":"Zhuolun Du","userId":"16686697190012944947"}},"outputId":"db9c3415-b9b7-443f-de7f-aae66aa1a59e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'DRB'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"j-J38pOLabG9"},"source":["## Feature engineering\n","\n","In this section, we're going to use our findings in the previous exercise to make a new feature out of the existing data using a process called feature engineering. Consider that (in addition to being great overall teams) the Golden State Warriors (2016) and Detroit Pistons (2004) are widely regarded as the best offensive and defensive teams of our time, respectively. If you look at the full correlation matrix it seems like PTS and oppPTS are correlated with winning, but not as much as DRB. This should seem surprising as you would expect that the points scored and allowed should be the best indicator of whether a team wins a game. \n","\n","By applying some domain knowledge to this problem, however, we might reason that it is not the individual two features that affect how often you win but rather the combination of those features. In the code below, we create a new feature called \"diffPTS\" (to represent difference in points scored by a team and points scored against a team), and then we check how it correlates with wins.\n"]},{"cell_type":"code","metadata":{"id":"1g1yj7_DfVZc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664125075179,"user_tz":240,"elapsed":46,"user":{"displayName":"Zhuolun Du","userId":"16686697190012944947"}},"outputId":"39132cb7-ff1b-4544-ea48-d5132296a1ea"},"source":["# Make new column in df\n","df['dffPTS'] = df.PTS - df.oppPTS  # new column data\n","dffPTS_corr = df[['dffPTS', 'W']].corr().iloc[0,1]  # get correlation with wins\n","\n","# Get highest correlation coefficient from original data\n","highest_orig_corr = df.corr().W.drop(['W', 'Playoffs', 'dffPTS']).abs().max()\n","\n","print(f'Using only the original features the highest correlation with wins was {highest_orig_corr:.3f},\\n \\\n","but our new feature had a much higher correlation with wins of {dffPTS_corr:.3f}')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using only the original features the highest correlation with wins was 0.411,\n"," but our new feature had a much higher correlation with wins of 0.971\n"]}]},{"cell_type":"markdown","metadata":{"id":"TrodQtgsxF3P"},"source":["By engineering this new feature dffPTS we have a feature that correlates with wins more than any of the original features! As a very brief aside (will not be tested), the `:.3f` in the print statment is called a format specifier, and the logic is explained [here.](https://www.python.org/dev/peps/pep-0498/#format-specifiers)"]},{"cell_type":"markdown","metadata":{"id":"GYaGkyBAiUqd"},"source":["# Linear Regression\n","\n","Linear regression can be used when the target (i.e., what you're trying to predict) is a continuous variable that can take any values from minus infinity to positive infinity. Let $y$ represent the target and $x_1,x_2,\\dots,x_K$ represent $K$ features (i.e., what you're using to predict the target). \n","\n","We use linear regression to find the best coefficients $\\beta_0,\\beta_1,\\dots,\\beta_K$, such that our predictions,\n","\n","$y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\dots + \\beta_Kx_K,$\n","\n","are as close as possible to the true target values, $\\hat{y}$. We define the error (i.e., residual) for a given observation as $\\hat{y} -y$. Then we choose our regression coefficients to minimize the mean squared error (MSE) between the true target values ($\\hat{y}$) and the predicted target values ($y$) across all data points. For example, suppose we observe $n$ data points of the form $(y_i,x_{i1},x_{i2},\\dots,x_{iK}), \\;i=1,\\dots,n$, then we would solve this optimization problem\n","\n","$$\n","\\begin{aligned}\n","\\min_{\\beta_0,\\beta_1,\\dots,\\beta_K} \\quad  & \\frac{1}{n}\\sum_{i=1}^n \\left( \\beta_0 + \\beta_1x_{i1} + \\beta_2x_{i2} + \\dots + \\beta_Kx_{iK} - \\hat{y}_i \\right)^2.     \\quad\\quad\\quad (1)\n","\\end{aligned}\n","$$\n","\n","We denote the coefficients that minimize (1) by $\\hat{\\beta}_0,\\hat{\\beta}_1,\\dots,\\hat{\\beta}_K$. "]},{"cell_type":"markdown","metadata":{"id":"JB2b2KyAxyGZ"},"source":["## Coding up the model\n","\n","In this course, we will mostly use the `scikit-learn` package to build predictive models. In `scikit-learn`, every model is defined as a class object that contains (amongst others), several standard methods:\n","\n","* **fit()**: Takes training features and target as input and uses that to fit the model (i.e., find the best parameters for a model).\n","* **predict()**: Takes testing features as input and uses that to predict target values (i.e., use the model).\n","* **score()**: Takes testing features and target as input and uses that to measure the error (i.e., evaluate model performance).\n","\n","\n","We will now build a linear regression model to predict the total number of wins using all of the numerical features. When building any model, we make sure that we split the data into reasonable training and testing sets. We then use  [`LinearRegression`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) and fit our model on the training data and predict on the target data."]},{"cell_type":"code","metadata":{"id":"9F7TDV8MgxXk"},"source":["# Split the data into training and testing sets\n","df_train = df[df.SeasonEnd<2012]\n","df_test = df[df.SeasonEnd>=2012]\n","\n","# Define features to remove from the feature data (i.e., X)\n","drop_for_X = ['W','Team','SeasonEnd','Playoffs']\n","\n","# Partition the training data into features and target\n","X_train = df_train.drop(columns=drop_for_X)\n","y_train = df_train.W\n","\n","# Fit the model\n","linreg = LinearRegression()\n","linreg.fit(X_train, y_train)\n","\n","# Partition the testing data into features and target\n","X_test = df_test.drop(columns=drop_for_X)\n","y_test = df_test.W\n","\n","# Predict the number of wins\n","y_test_predictions = linreg.predict(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"brm2gfODmAAL"},"source":["In the codeblock above, we used the `predict()` method to predict $y$ for each data point (i.e., row) in `X_test`. To determine how _good_ those predictions were you should use the score function, as follows:"]},{"cell_type":"code","metadata":{"id":"XDMIWnXol_Hi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664125075180,"user_tz":240,"elapsed":36,"user":{"displayName":"Zhuolun Du","userId":"16686697190012944947"}},"outputId":"f711d0e1-78cb-438f-8674-82a0892bda59"},"source":["train_score = linreg.score(X_train, y_train)\n","test_score = linreg.score(X_test, y_test)\n","\n","print(f'The train score is {train_score:.3f} and the test score is {test_score:.3f}')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The train score is 0.944 and the test score is 0.888\n"]}]},{"cell_type":"markdown","metadata":{"id":"GsXhqUp9oe1M"},"source":["The \"score\" for linear regression is the _coefficient of determination_ (i.e., $R^2$). In the space above, we calculated the score of the training and testing data, and we found that the model performed better on the training data ($R^2$=0.944) than it did on the testing data ($R^2$=0.888). In general the model will perform better on the data it was trained on than data it is seeing for the first time (i.e., testing set). Although most (if not all) models in `scikit-learn` have a score method, the score that `score` evaluates depends on the model. Please keep this in mind when you write a report. \n","\n","In a `LinearRegression` model, the `coef_` attribute returns the values for $\\beta$ and the `intercept_` attribute stores the value fo $\\beta_0$."]},{"cell_type":"code","metadata":{"id":"4jLoNgNSoRdJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664125075181,"user_tz":240,"elapsed":27,"user":{"displayName":"Zhuolun Du","userId":"16686697190012944947"}},"outputId":"2ac961da-0a05-4df8-c5c3-04a99c3c9129"},"source":["betas = pd.Series(linreg.coef_, index=X_train.columns)\n","betas = betas.append(pd.Series({\"Intercept\": linreg.intercept_}))\n","print(betas)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["PTS          -1.032659e+10\n","oppPTS       -4.945743e+09\n","FG            3.136950e+10\n","FGA           1.995394e+10\n","2P           -8.248390e+08\n","2PA          -1.995394e+10\n","3P            1.444749e+10\n","3PA          -1.995394e+10\n","FT            1.527233e+10\n","FTA          -1.105242e-03\n","ORB           1.955840e-03\n","DRB           2.634602e-03\n","AST           1.160074e-03\n","STL           1.172673e-03\n","BLK           3.770994e-03\n","TOV          -2.041234e-03\n","Conference    1.902110e-01\n","dffPTS       -4.945743e+09\n","Intercept     3.897555e+01\n","dtype: float64\n"]}]},{"cell_type":"markdown","metadata":{"id":"oLysXYhKpg9a"},"source":["You should observe that some of the beta coefficients (e.g., for `oppPTS` and `dffPTS`) are identical, which is the sign of a problem. The problem is that many of the features are highly correlated with each other, and we are therefore violating the assumption of no multi-collinearity!\n","\n","### Exercise\n","1. In the space below, plot the correlation matrix. Which two features are the most correlated?"]},{"cell_type":"code","metadata":{"id":"9kTsqB-To1IO"},"source":["# Write your code here.\n","\n","# -------------------\n","\n","\n","# -------------------"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_train.corr()[df_train.corr().abs() > 0.99]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":793},"id":"QMNKw29he8r0","executionInfo":{"status":"ok","timestamp":1664125075181,"user_tz":240,"elapsed":16,"user":{"displayName":"Zhuolun Du","userId":"16686697190012944947"}},"outputId":"f2f3a376-fd74-4354-cf78-bcda2490b43d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["            SeasonEnd    W  PTS  oppPTS   FG  FGA   2P  2PA        3P  \\\n","SeasonEnd         1.0  NaN  NaN     NaN  NaN  NaN  NaN  NaN       NaN   \n","W                 NaN  1.0  NaN     NaN  NaN  NaN  NaN  NaN       NaN   \n","PTS               NaN  NaN  1.0     NaN  NaN  NaN  NaN  NaN       NaN   \n","oppPTS            NaN  NaN  NaN     1.0  NaN  NaN  NaN  NaN       NaN   \n","FG                NaN  NaN  NaN     NaN  1.0  NaN  NaN  NaN       NaN   \n","FGA               NaN  NaN  NaN     NaN  NaN  1.0  NaN  NaN       NaN   \n","2P                NaN  NaN  NaN     NaN  NaN  NaN  1.0  NaN       NaN   \n","2PA               NaN  NaN  NaN     NaN  NaN  NaN  NaN  1.0       NaN   \n","3P                NaN  NaN  NaN     NaN  NaN  NaN  NaN  NaN  1.000000   \n","3PA               NaN  NaN  NaN     NaN  NaN  NaN  NaN  NaN  0.994511   \n","FT                NaN  NaN  NaN     NaN  NaN  NaN  NaN  NaN       NaN   \n","FTA               NaN  NaN  NaN     NaN  NaN  NaN  NaN  NaN       NaN   \n","ORB               NaN  NaN  NaN     NaN  NaN  NaN  NaN  NaN       NaN   \n","DRB               NaN  NaN  NaN     NaN  NaN  NaN  NaN  NaN       NaN   \n","AST               NaN  NaN  NaN     NaN  NaN  NaN  NaN  NaN       NaN   \n","STL               NaN  NaN  NaN     NaN  NaN  NaN  NaN  NaN       NaN   \n","BLK               NaN  NaN  NaN     NaN  NaN  NaN  NaN  NaN       NaN   \n","TOV               NaN  NaN  NaN     NaN  NaN  NaN  NaN  NaN       NaN   \n","Conference        NaN  NaN  NaN     NaN  NaN  NaN  NaN  NaN       NaN   \n","Playoffs          NaN  NaN  NaN     NaN  NaN  NaN  NaN  NaN       NaN   \n","dffPTS            NaN  NaN  NaN     NaN  NaN  NaN  NaN  NaN       NaN   \n","\n","                 3PA  ...  FTA  ORB  DRB  AST  STL  BLK  TOV  Conference  \\\n","SeasonEnd        NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN         NaN   \n","W                NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN         NaN   \n","PTS              NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN         NaN   \n","oppPTS           NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN         NaN   \n","FG               NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN         NaN   \n","FGA              NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN         NaN   \n","2P               NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN         NaN   \n","2PA              NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN         NaN   \n","3P          0.994511  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN         NaN   \n","3PA         1.000000  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN         NaN   \n","FT               NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN         NaN   \n","FTA              NaN  ...  1.0  NaN  NaN  NaN  NaN  NaN  NaN         NaN   \n","ORB              NaN  ...  NaN  1.0  NaN  NaN  NaN  NaN  NaN         NaN   \n","DRB              NaN  ...  NaN  NaN  1.0  NaN  NaN  NaN  NaN         NaN   \n","AST              NaN  ...  NaN  NaN  NaN  1.0  NaN  NaN  NaN         NaN   \n","STL              NaN  ...  NaN  NaN  NaN  NaN  1.0  NaN  NaN         NaN   \n","BLK              NaN  ...  NaN  NaN  NaN  NaN  NaN  1.0  NaN         NaN   \n","TOV              NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  1.0         NaN   \n","Conference       NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN         1.0   \n","Playoffs         NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN         NaN   \n","dffPTS           NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN         NaN   \n","\n","            Playoffs  dffPTS  \n","SeasonEnd        NaN     NaN  \n","W                NaN     NaN  \n","PTS              NaN     NaN  \n","oppPTS           NaN     NaN  \n","FG               NaN     NaN  \n","FGA              NaN     NaN  \n","2P               NaN     NaN  \n","2PA              NaN     NaN  \n","3P               NaN     NaN  \n","3PA              NaN     NaN  \n","FT               NaN     NaN  \n","FTA              NaN     NaN  \n","ORB              NaN     NaN  \n","DRB              NaN     NaN  \n","AST              NaN     NaN  \n","STL              NaN     NaN  \n","BLK              NaN     NaN  \n","TOV              NaN     NaN  \n","Conference       NaN     NaN  \n","Playoffs         1.0     NaN  \n","dffPTS           NaN     1.0  \n","\n","[21 rows x 21 columns]"],"text/html":["\n","  <div id=\"df-2d9c4fd8-d3c1-402f-ad98-60a4d0291ce7\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>SeasonEnd</th>\n","      <th>W</th>\n","      <th>PTS</th>\n","      <th>oppPTS</th>\n","      <th>FG</th>\n","      <th>FGA</th>\n","      <th>2P</th>\n","      <th>2PA</th>\n","      <th>3P</th>\n","      <th>3PA</th>\n","      <th>...</th>\n","      <th>FTA</th>\n","      <th>ORB</th>\n","      <th>DRB</th>\n","      <th>AST</th>\n","      <th>STL</th>\n","      <th>BLK</th>\n","      <th>TOV</th>\n","      <th>Conference</th>\n","      <th>Playoffs</th>\n","      <th>dffPTS</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>SeasonEnd</th>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>W</th>\n","      <td>NaN</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>PTS</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>oppPTS</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>FG</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>FGA</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2P</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2PA</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3P</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1.000000</td>\n","      <td>0.994511</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3PA</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.994511</td>\n","      <td>1.000000</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>FT</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>FTA</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>ORB</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>DRB</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>AST</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>STL</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>BLK</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>TOV</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>Conference</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>Playoffs</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>dffPTS</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>21 rows Ã— 21 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2d9c4fd8-d3c1-402f-ad98-60a4d0291ce7')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-2d9c4fd8-d3c1-402f-ad98-60a4d0291ce7 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-2d9c4fd8-d3c1-402f-ad98-60a4d0291ce7');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["sns.heatmap(df_train.corr())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":333},"id":"-pm-r2C3efE2","executionInfo":{"status":"ok","timestamp":1664125075855,"user_tz":240,"elapsed":688,"user":{"displayName":"Zhuolun Du","userId":"16686697190012944947"}},"outputId":"015ac714-0642-40da-8d72-086f913ec22a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7ff4b0c04c10>"]},"metadata":{},"execution_count":16},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 2 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"sOZUiIS1vEyd"},"source":["___\n","**Question 1 answer:** \n","___\n","\n","## Correlated features\n","Below we define a function and describe it with a [_docstring_](https://www.datacamp.com/community/tutorials/docstrings-python?utm_source=adwords_ppc&utm_campaignid=898687156&utm_adgroupid=48947256715&utm_device=c&utm_keyword=&utm_matchtype=b&utm_network=g&utm_adpostion=&utm_creative=332602034352&utm_targetid=aud-392016246653:dsa-429603003980&utm_loc_interest_ms=&utm_loc_physical_ms=9061009&gclid=Cj0KCQjwy8f6BRC7ARIsAPIXOjhfMN9Oj6QCqNfMMDgZYqFFwp7yv6P9V_agl4PtR3O6o95GidfErGYaAsSCEALw_wcB) (i.e., the string at the begining of the function). A docstring should be present at the begining of most functions contained in reputable python packages.  We'll use this function to go through every feature and count the number of times this feature is correlated or anti-correlated with another feature by more than `threshold`. We set the default value of `threshold` to 0.7. \n"]},{"cell_type":"code","metadata":{"id":"s5asXhxwqWl2","pycharm":{"is_executing":false},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664125075855,"user_tz":240,"elapsed":16,"user":{"displayName":"Zhuolun Du","userId":"16686697190012944947"}},"outputId":"3550075c-1d28-4ddc-865c-703fc7ee12ec"},"source":["# Define a function\n","def print_heavily_correlated_features(df, threshold=0.7):\n","  \"\"\"\n","  For each feature in \"df\", this function counts the number of features that \n","  have a correlation coefficient with that is higher than \"threshold\".\n","\n","  Parameters\n","  ----------\n","    df: pandas DataFrame type \n","        Contains the features for several data points\n","    threshold: float type \n","        he threshold for which \"heavily correlated\" is defined.\n","  \"\"\"\n","\n","  corr = df.corr().abs()  # calculate the correlation matrix\n","  corr = corr[corr > threshold]  # a mask of features that are heavily correlated\n","\n","  # Print out the \"heavily correlated\" counts\n","  print(corr.count().sort_values(ascending=False) - 1)  \n","\n","# Execute the function\n","print_heavily_correlated_features(df_train)  "],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2P            9\n","2PA           9\n","SeasonEnd     7\n","FG            7\n","PTS           6\n","FGA           6\n","oppPTS        5\n","3P            4\n","3PA           4\n","ORB           3\n","AST           3\n","Playoffs      2\n","dffPTS        2\n","W             2\n","FTA           1\n","TOV           1\n","FT            1\n","DRB           0\n","STL           0\n","BLK           0\n","Conference    0\n","dtype: int64\n"]}]},{"cell_type":"markdown","metadata":{"id":"Ewnyfp_NzV1e"},"source":["### Exercise\n","1. Why did we run the above function on df_train rather than df?\n","\n","2. In the codeblock below, we created a new DataFrame called `df_reduced`. Use it to fit a better regression model by following these steps: \n","\n","i)  From `df_reduced` remove the 5 features most heavily susceptible to multi-collinearity (i.e., 2P, 2PA, FG, PTS, FGA).  \n","ii) Then, fit a new linear regression model `linreg_reduced` to this data set using the same train-test split.  \n","iii) Report the score and the beta coefficients.\n","___\n","**Question 1 answer:**\n","\n","___\n"]},{"cell_type":"code","metadata":{"id":"rNmcVNYHqYZZ"},"source":["# We have made a copy of the data frame\n","df_reduced = df.copy()\n","\n","# REMEMBER: drop the features listed in drop_for_X from X_train and X_test\n","\n","# Write your code here.\n","\n","# -------------------\n","\n","\n","\n","# -------------------\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["COLUMNS_TO_REMOVE = [ '2P', '2PA', 'FG', 'PTS', 'FGA']\n","# drop_for_X = ['W','Team','SeasonEnd','Playoffs']\n","\n","df_reduced = df_reduced.drop(columns=COLUMNS_TO_REMOVE)\n","\n","df_train = df_reduced[df_reduced.SeasonEnd<2012]\n","df_test = df_reduced[df_reduced.SeasonEnd>=2012]\n","\n","X_train = df_train.drop(columns=drop_for_X)\n","y_train = df_train.W\n","\n","linreg_reduced = LinearRegression()\n","linreg_reduced.fit(X_train, y_train)\n","\n","X_test = df_test.drop(columns=drop_for_X)\n","y_test = df_test.W\n","\n","train_score = linreg_reduced.score(X_train, y_train)\n","test_score = linreg_reduced.score(X_test, y_test)\n","print('The train score is {} and the test score is {}'.format(train_score, test_score))\n","\n","# calculate betas\n","betas = pd.Series(linreg_reduced.coef_, index=X_train.columns)\n","betas = betas.append(pd.Series({\"Intercept\": linreg_reduced.intercept_}))\n","print(betas)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0r9tagXSixJC","executionInfo":{"status":"ok","timestamp":1664057912387,"user_tz":240,"elapsed":6,"user":{"displayName":"Zhuolun Du","userId":"16686697190012944947"}},"outputId":"da6bcf6e-f0b5-4032-d25a-afaab4f9e9b1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The train score is 0.9436031160878491 and the test score is 0.9324329969540632\n","oppPTS        -0.000136\n","3P            -0.007007\n","3PA            0.002766\n","FT             0.000195\n","FTA           -0.000227\n","ORB           -0.000462\n","DRB            0.001097\n","AST            0.001251\n","STL           -0.000716\n","BLK            0.003887\n","TOV           -0.000670\n","Conference     0.203804\n","dffPTS         0.032004\n","Intercept     37.067376\n","dtype: float64\n"]}]},{"cell_type":"markdown","metadata":{"id":"sZ2fOwIq16Fd"},"source":["You should notice that your model now gives a much higher score on the test set! Furthermore, the test score is more or less the same as the train score.\n","\n","## Overfitting\n","\n","In the first model that used all of the features (i.e., `linreg`), the train score was much higher than the test score. This means that the model was _overfitting_ to the training set. Overfitting occurs when the model identifies relationships that are unique to the training set and do not generalize to unseen (testing) data. Note that in the model with fewer features (i.e., the reduced model) actually performed much better on the out-of-sample data because it did not overfit. \n","\n","Multi-collinearity can cause overfitting, but there are other causes that we won't cover in this lab including:\n","\n","1. Small dataset\n","2. Complex model \n","3. Hidden biases in the data (e.g., multi-collinearity)\n","\n","Another important observation is that the $\\beta$ values make a lot more sense now in terms of how they would affect the number of wins of a given team.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"nvYb2dEc0h1D"},"source":["### Exercise\n","1. How many more three point shots does a team need to score in a given season in order to win 1 additional game?\n","\n","2. According to your model, does having more offensive rebounds help or hurt a team's chances of winning games? Does this make sense? Why or why not? Provide details justifying your answer.\n","\n","___\n","**Question 1 answer**\n","\n","\n","___\n","**Question 2 answer**:\n","\n","\n","___"]},{"cell_type":"markdown","metadata":{"id":"WxSmh7uk7vzh"},"source":["# Regularization\n","\n","Previously, we saw that the model was overfitting because it had too many features. To reduce overfitting, we used our domain knowledge to remove features from the model using a process called _manual feature selection_. If we have a poor understanding of the problem domain and/or we suspect our model is overfitting then doing manual feature selection is difficult. \n","\n","A more automated way to reduce overfitting that requires no domain knowledge is _regularization_. This technique is especially useful in applications with a _relatively large_ number of features ($K$) compared to the number of samples ($n$) in the training dataset. A __very rough__ rule of thumb is that you should have no more than $\\sqrt n$ features in your model (i.e., $K\\le\\sqrt n$). Regularization is a very general operation that can be applied to most models. In this section, we'll explain regularization in the context of linear regression.\n","\n","In regularized linear regression, we add the term $\\frac{1}{C}\\sum_{k=1}^K |\\beta_k|^p$ to the objective of Equation (1), where $p$ is a number that denotes the type of regularization (e.g., L1, L2) and $C$ is a parameter learned by the model (or occasionally selected by the user). The value $\\frac{1}{C}$ is called the _strength of regularization_ (a low value of C corresponds to a high regularization stength). Intuitively, you can think of regularization as a process that penalizes non-zero regression coefficients (i.e., $\\beta > 0$), but keep in mind that different types of regularization produce different results. There are two common types of regularization:\n","\n"," 1. __L1-regularization ($p=1$):__ Also called _LASSO_ regression, is frequently used for feature selection because it implicitly produces a sparse solution, i.e., only a small portion of the regression coefficients will be non-zero. Using L1-regularization, we can rewrite (1) as             \n","    \\begin{aligned} \n","        \\min_{\\beta_0,\\beta_1,\\dots,\\beta_K} \\quad  & \\frac{1}{n}\\sum_{i=1}^n \\left( \\beta_0 + \\beta_1x_{i1} + \\beta_2x_{i2} + \\dots + \\beta_Kx_{iK} - y_i \\right)^2 + \\frac{1}{C} \\sum_{k=1}^K |\\beta_k|.\n","    \\end{aligned}\n","               \n"," 2.  __L2-regularization ($p=2$):__ Also called _ridge_ regression, is frequently used to produce a model that tries to use all of the available features. Using L2-regularization, we can rewrite (1) as\n","        \\begin{aligned}\n","            \\min_{\\beta_0,\\beta_1,\\dots,\\beta_K} \\quad  & \\frac{1}{n}\\sum_{i=1}^n \\left( \\beta_0 + \\beta_1x_{i1} + \\beta_2x_{i2} + \\dots + \\beta_Kx_{iK} - y_i \\right)^2 + \\frac{1}{C} \\sum_{k=1}^K (\\beta_k)^2.\n","        \\end{aligned}\n","        \n","\n","Both methods reduce the sum of coefficients and prevent overfitting, however, in general each methods has different use cases. Also, note that L2-regularization is more computationally efficient than L1-regularization.\n"]},{"cell_type":"markdown","metadata":{"id":"2QckZK337QNN"},"source":["\n","## Cross-validation\n","_Cross-validation_ is a process for selecting model hyper-parameters (e.g., $C$) that generalize to out-of-sample data. Cross-validation is performed in $m$ rounds (or $m$-folds, typically called $m$-fold cross validation - more on that in Lab 3). In each round the training set is split into two subsets (1) a subset that the model is trained on, and (2) a subset that the model is evaluated on. After the $m$ rounds are complete, an aggregate measure of performance (e.g., average score) is used to measure model performance. \n","\n","We can use cross validation to search for the best parameter out of a list. For example, we could look for the best parameter $C$ for a regression model out of the list [0.1, 1, 10, 100]. Cross-validation would perform $m$ rounds (typically $m=5$ or $m=10$) for each element in that list, and give us the best performing model (i.e., the best available $C$). \n","\n","Let's try building a new linear regression model with regularization. We'll pretend that we know nothing about basketball. In this case we use the [`LassoCV` model from scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html#sklearn.linear_model.LassoCV) to build an L1-regularized linear regression model. The `LassoCV` model automatically applies cross-validation to find the best value for $C$."]},{"cell_type":"code","metadata":{"id":"IA1hpWmf1i_J","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664125111793,"user_tz":240,"elapsed":6,"user":{"displayName":"Zhuolun Du","userId":"16686697190012944947"}},"outputId":"f8fded4e-4c15-43db-9ece-eee90d51676b"},"source":["# Let's go back to the original data set without the removed features\n","# Split the data into training and testing sets\n","df_train = df[df.SeasonEnd<2012]\n","df_test = df[df.SeasonEnd>=2012]\n","\n","# Partition the training data into features and target\n","X_train = df_train.drop(columns=drop_for_X)\n","y_train = df_train.W\n","\n","# Fit the model\n","lasso = LassoCV()\n","lasso.fit(X_train, y_train)\n","\n","# Partition the testing data into features and target\n","X_test = df_test.drop(columns=drop_for_X)\n","y_test = df_test.W\n","\n","# calculate the score\n","train_score = lasso.score(X_train, y_train)\n","test_score = lasso.score(X_test, y_test)\n","print(f'The train score is {train_score:.3} and the test score is {test_score:.3}')\n","\n","# calculate betas\n","betas = pd.Series(lasso.coef_, index=X_train.columns)\n","betas = betas.append(pd.Series({\"Intercept\": lasso.intercept_}))\n","print(betas)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The train score is 0.942 and the test score is 0.949\n","PTS            0.000000\n","oppPTS        -0.000000\n","FG             0.000000\n","FGA           -0.000000\n","2P            -0.000000\n","2PA           -0.000000\n","3P             0.000000\n","3PA            0.000000\n","FT            -0.000000\n","FTA           -0.000000\n","ORB           -0.000000\n","DRB            0.000000\n","AST            0.000000\n","STL           -0.000000\n","BLK            0.000000\n","TOV           -0.000000\n","Conference     0.000000\n","dffPTS         0.032282\n","Intercept     41.000000\n","dtype: float64\n"]}]},{"cell_type":"markdown","metadata":{"id":"RNs2xQTp4Qwi"},"source":["You should observe that the LASSO model performs better than our manually reduced model! Remember that the model automatically performed cross-validation to get the best regularization strength. Also notice that the beta values are approximately zero for nearly every feature except for dffPTS. \n","\n","### Exercise\n","1. Use the attribute `alpha_` to find the regularization strength (i.e., $\\frac{1}{C}$) for the model `lasso`. Keep in mind that the attribute `alpha_` returns $\\alpha = \\frac{1}{C}$.\n","\n","2. Would you prefer this model (`lasso`) or the one with manual feature selection (`linreg_reduced`) to better understand what it takes to win?\n","\n","3. Try building a LASSO model with the reduced data set (`df_reduced`). Do you expect it to differ from the above LASSO model? How does it perform?\n","\n","4. In the space below, fit a ridge regression model on the original dataset (`df`) using [`RidgeCV` from scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html#sklearn.linear_model.RidgeCV), and call that model `ridge`. Compare the test score and the betas with the `lasso` model. How do the models differ with respect to score and betas? Which model would you use to understand the effects of features on winning?\n"]},{"cell_type":"code","metadata":{"id":"OclDpbSW4yhO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663105605207,"user_tz":240,"elapsed":221,"user":{"displayName":"Craig Fer","userId":"10199331155832657902"}},"outputId":"609e228a-f6e6-4792-f1b3-c45c40991779"},"source":["# Question 1\n","\n","# Write your code here.\n","\n","# -------------------\n","\n","\n","# -------------------\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The regularization strength is 1/C = 43.726\n"]}]},{"cell_type":"code","source":["lasso.alpha_"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pMbMoe9olxgv","executionInfo":{"status":"ok","timestamp":1664125206497,"user_tz":240,"elapsed":410,"user":{"displayName":"Zhuolun Du","userId":"16686697190012944947"}},"outputId":"569281c9-32a1-49e1-b359-2e234481d8b2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["43.72649844696334"]},"metadata":{},"execution_count":21}]},{"cell_type":"markdown","metadata":{"id":"I9meQRgBKwz4"},"source":["___\n","**Question 2 answer:**\n","\n","\n","___\n","**Question 3 answer:**\n","\n","___\n","\n"]},{"cell_type":"code","source":["# Question 3 code\n","\n","# Write your code here.\n","\n","# -------------------\n","\n","\n","\n","# -------------------\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L6gUvIBayJNR","executionInfo":{"status":"ok","timestamp":1663105605208,"user_tz":240,"elapsed":17,"user":{"displayName":"Craig Fer","userId":"10199331155832657902"}},"outputId":"fb73f8ac-e8c0-487a-acfe-1053cf53ca76"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The train score is 0.942 and the test score is 0.949\n"]}]},{"cell_type":"markdown","metadata":{"id":"qLEXpD6CyLW4"},"source":["___\n","**Question 4 answer:**\n","\n","\n","___\n","\n"]},{"cell_type":"code","metadata":{"id":"97n6tSdwJrSa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663105605384,"user_tz":240,"elapsed":186,"user":{"displayName":"Craig Fer","userId":"10199331155832657902"}},"outputId":"680bf1e5-d987-428d-9eb9-bd948590a41c"},"source":["# Question 4 code\n","\n","# Write your code here.\n","\n","# -------------------\n","\n","\n","\n","# -------------------"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The train score is 0.944 and the test score is 0.89\n","PTS            0.008856\n","oppPTS        -0.011170\n","FG             0.003202\n","FGA           -0.000576\n","2P             0.003958\n","2PA           -0.001742\n","3P            -0.000756\n","3PA            0.001166\n","FT             0.003209\n","FTA           -0.001101\n","ORB            0.001959\n","DRB            0.002638\n","AST            0.001155\n","STL            0.001179\n","BLK            0.003776\n","TOV           -0.002044\n","Conference     0.180656\n","dffPTS         0.020026\n","Intercept     38.852344\n","dtype: float64\n"]}]},{"cell_type":"code","source":["df_train = df[df.SeasonEnd<2012]\n","df_test = df[df.SeasonEnd>=2012]\n","\n","X_train = df_train.drop(columns=drop_for_X)\n","y_train = df_train.W\n","\n","# Fit the model\n","ridge = RidgeCV()\n","ridge.fit(X_train, y_train)\n","\n","# Partition the testing data into features and target\n","X_test = df_test.drop(columns=drop_for_X)\n","y_test = df_test.W\n","\n","# calculate the score\n","train_score = ridge.score(X_train, y_train)\n","test_score = ridge.score(X_test, y_test)\n","print(f'The train score is {train_score:.3} and the test score is {test_score:.3}')\n","\n","# calculate betas\n","betas = pd.Series(ridge.coef_, index=X_train.columns)\n","betas = betas.append(pd.Series({\"Intercept\": ridge.intercept_}))\n","print(betas)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I37S0Nwrmiqp","executionInfo":{"status":"ok","timestamp":1664125490415,"user_tz":240,"elapsed":267,"user":{"displayName":"Zhuolun Du","userId":"16686697190012944947"}},"outputId":"7aa28bae-f3c3-455b-8b2d-d4b1bb870813"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The train score is 0.944 and the test score is 0.89\n","PTS            0.008856\n","oppPTS        -0.011170\n","FG             0.003202\n","FGA           -0.000576\n","2P             0.003958\n","2PA           -0.001742\n","3P            -0.000756\n","3PA            0.001166\n","FT             0.003209\n","FTA           -0.001101\n","ORB            0.001959\n","DRB            0.002638\n","AST            0.001155\n","STL            0.001179\n","BLK            0.003776\n","TOV           -0.002044\n","Conference     0.180656\n","dffPTS         0.020026\n","Intercept     38.852344\n","dtype: float64\n"]}]},{"cell_type":"code","source":["ridge.alpha_"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iYETuevznNCT","executionInfo":{"status":"ok","timestamp":1664125565419,"user_tz":240,"elapsed":313,"user":{"displayName":"Zhuolun Du","userId":"16686697190012944947"}},"outputId":"382ce8c7-8767-4201-c02c-5860d3820af4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["10.0"]},"metadata":{},"execution_count":23}]},{"cell_type":"markdown","metadata":{"id":"67N_ItrIAS5f"},"source":["___\n","**Question 4 answer:**\n","\n","\n","___\n"]},{"cell_type":"markdown","source":["# Learning Check Point\n","\n","Thus far, we have used linear regression to *understand* what leads to more wins. We explored feature engineering (i.e., making the diffPTS feature). We discussed two types of regularization to avoid overfitting. We also briefly discussed cross-validation (a topic we will explain in greater detail in the next lab). \n","\n","We will now move to logistic regression and begin *predicting*. "],"metadata":{"id":"imx0qvwQy7Qe"}},{"cell_type":"markdown","metadata":{"id":"TmW4lnDiKsu9"},"source":["# Logistic Regression\n","\n","Logistic regression can be used when the target is a categorical variable that  takes values of 0 and 1. Recall that in linear regression, $y$ is modeled as a linear function of $\\mathbf{x}$; in logistic regression, we model the _logit_ or _log-odds ratio_ as a linear function of $\\mathbf{x}$. That is,\n","\n","$$\n","\\begin{aligned}\n","    \\mathrm{logit}(y) = \\log\\left(\\frac{y}{1-y}\\right) = \\beta_0 + \\beta_1 x_1 + \\dots + \\beta_K x_K\n","\\end{aligned}\n","$$\n","\n","We can rewrite the logit equation to obtain the probability,\n","\n","$$\n","\\begin{aligned}\n","y = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 x_1 + \\dots + \\beta_K x_K)}}\n","\\end{aligned}\n","$$\n","\n","In order to turn the logit into a prediction, we apply a threshold rule $T(y)$. For example, a threshold rule of $0.5$ corresponds to\n","$$ T(y) = \n","\\begin{cases}\n","     1,& \\text{ if } y \\geq 0.5, \\\\\n","     0,& \\text{ if } y \\leq 0.5.\n","\\end{cases}$$\n","\n"]},{"cell_type":"markdown","metadata":{"id":"-Bzfd-eYDIdi"},"source":["\n","## Evaluating model performance\n","\n","The standard way to score (i.e., evaluate performance) a logistic regression is via mean accuracy. This is equal to the proportion of data points $i = 1, 2, \\dots, n$ for which $T(y_i) = \\hat{y}_i$. We calculate it as \n","$1 - \\frac{\\sum_{i=1}^N |T(y_i) - \\hat{y}_i| }{N}$. We can think of this scoring metric for logistic regression as something that is analogous to the $R^2$ metric for linear regression. \n","\n","For a binary classification problem, although the accuracy of a model is a great measure of its performance, accuracy fails to reveal the type of errors that the model makes. There are two main types of errors: (1) false positives (FP), where a value of $1$ is predicted (i.e., $y = 1$) when the true value is $0$ (i.e., $\\hat{y} = 0$); and (2) false negatives (FN), where a value of $0$ is predicted (i.e., $y = 0$) when the true value is $1$ (i.e., $\\hat{y} = 1$). A correctly classified point is a true positive (TP) or true negative (TN) when a value of $1$ or $0$ is correctly predicted, respectively. There are several common summary statistics that summarize the frequency of different error types that are summarized in the following table.\n","\n","| Statistic                             | Calculation    | Definition |\n","|:--------------------------------------|:--------------:|:-----------|\n","| Recall/Sensitivity/True Positive Rate | TP / (TP + FN) | the proportion of $y_i = 1$ that were correctly labelled |\n","| Fall-out/False Positive Rate          | FP / (FP + TN) | the proportion of $y_i = 0$ that were incorrectly labelled |\n","| Precision/Positive Predictive Value   | TP / (TP + FP) | the proportion of $T(\\hat{y}_i) = 1$ that match the data |\n","| False Omission Rate                   | FN / (FN + TN) | the proportion of $T(\\hat{y}_i) = 0$ that don't match the data |\n","\n","In general, true positive rate (TPR) and false positive rate (FPR) are the most common of the ratios presented above. TPR is a measure of how often we correctly identify when the target is true (i.e., $y = 1$ and $\\hat{y} = 1$), and FPR is a measure of how often we incorrectly identify when the target is true (i.e., $y = 1$ and $\\hat{y}=0$). There are many other metrics that quantify model error, and the best metric to use depends on the application of the model. We can summarize all of this information inside a confusion matrix.\n","\n","![alt text](https://miro.medium.com/max/1194/0*wKaznIJzZF54b87B.jpg)"]},{"cell_type":"markdown","metadata":{"id":"378hdG56DMgP"},"source":["\n","## Coding the model\n","\n","Remember that linear regression predicts continuous target values, and logistic regression predicts target binary values (i.e., categorical). While we used linear regression to **understand** what leads to wins within a season, we will now use logistic regression to **predict** whether a team will make the playoffs in the following season, using only information from the current season (e.g., use 2015 data to predict `'Playoffs'` in 2016).\n","\n","\n","In the code block below, we do some data processing to prepare the data you need to predict whether or not a team will qualify for playoffs next year. We use the column `'NextYearPlayoffs'` to denote whether or not a team will (`'NextYearPlayoffs'` = 1) or will not (`'NextYearPlayoffs'` = 0) make playoffs. The code block below generates this feature using [multi indexing](https://pandas.pydata.org/pandas-docs/stable/user_guide/advanced.html), but we don't expect you to understand multi-indexing at this stage in the course  (i.e., the code block immediately below will not come up in any capacity during Quiz 2).\n","\n"]},{"cell_type":"code","metadata":{"id":"4up7PQA0muda"},"source":["\"\"\"In this codeblock, we process the data for you using functions that you DO \n","NOT need to be familiar with right now (you won't be tested on this type of \n","data manipulation in Quiz 2). We add the code here for your own curiosity.\"\"\"\n","\n","# Make a copy of the original DataFrame\n","X = df.copy()\n","\n","# Change the index to Team and Season\n","X = X.set_index(['Team', 'SeasonEnd'])\n","# Keep SeasonEnd as one of the columns\n","X['SeasonEnd'] = X.index.get_level_values(1).values \n","\n","# Get y data (i.e., if they make playoffs next year)\n","y = pd.concat((df['Team'], \n","               df['SeasonEnd']-1, \n","               df['Playoffs'].rename('NextYearPlayoffs')\n","              ), \n","              axis=1)\n","# Set the index to the same convention as X\n","y = y.set_index(['Team', 'SeasonEnd'])\n","\n","# Get intersection of indicies between X and y\n","index_intersection = X.index.intersection(y.index)\n","X = X.loc[index_intersection]  # Season stats\n","y = y.loc[index_intersection]  # Whether or no team makes playoffs next year\n","\n","df_nextyear = pd.concat([X,y], axis=1) # Create the new df_nextyear\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M9UMlfW2DN3v"},"source":["\n","### Exercise\n","1. In the space below, fit a [`LogisticRegression`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) model called `logreg` to predict the target (from the column \"NextYearPlayoffs\" in `df_nextyear`). We need to drop `SeasonEnd` and `NextYearPlayoffs` from `X_train` or `X_test`."]},{"cell_type":"code","source":["df_nextyear"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":599},"id":"rAozs6bUrx04","executionInfo":{"status":"ok","timestamp":1664126757034,"user_tz":240,"elapsed":5,"user":{"displayName":"Zhuolun Du","userId":"16686697190012944947"}},"outputId":"9f850b86-5e0e-41f6-c3d3-33a65d673848"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                W    PTS  oppPTS    FG   FGA    2P   2PA   3P  \\\n","Team                SeasonEnd                                                   \n","Philadelphia 76ers  2014       19   8155    9012  3108  7150  2531  5303  577   \n","Detroit Pistons     2004       54   7388    6909  2747  6314  2414  5346  333   \n","San Antonio Spurs   2004       57   7501    6909  2842  6434  2434  5294  408   \n","Indiana Pacers      2004       61   7493    7021  2753  6322  2304  5041  449   \n","Cleveland Cavaliers 1997       42   7173    7022  2704  5972  2221  4688  483   \n","...                            ..    ...     ...   ...   ...   ...   ...  ...   \n","Denver Nuggets      1981       37   9986   10025  3784  7960  3754  7815   30   \n","                    1983       45  10105   10054  3951  7999  3927  7873   24   \n","                    1984       38  10147   10237  3935  7983  3858  7728   77   \n","                    1982       46  10371   10328  3980  7656  3940  7507   40   \n","                    1991       20   9828   10723  3901  8868  3601  7809  300   \n","\n","                                3PA    FT  ...   DRB   AST  STL  BLK   TOV  \\\n","Team                SeasonEnd              ...                               \n","Philadelphia 76ers  2014       1847  1362  ...  2556  1791  765  330  1384   \n","Detroit Pistons     2004        968  1561  ...  2492  1702  659  570  1241   \n","San Antonio Spurs   2004       1140  1409  ...  2669  1676  661  537  1203   \n","Indiana Pacers      2004       1281  1538  ...  2452  1774  726  411  1182   \n","Cleveland Cavaliers 1997       1284  1282  ...  2159  1714  655  315  1188   \n","...                             ...   ...  ...   ...   ...  ...  ...   ...   \n","Denver Nuggets      1981        145  2388  ...  2497  2030  720  380  1444   \n","                    1983        126  2179  ...  2524  2336  789  352  1496   \n","                    1984        255  2200  ...  2444  2482  711  352  1344   \n","                    1982        149  2371  ...  2443  2272  664  368  1470   \n","                    1991       1059  1726  ...  2530  2005  856  406  1332   \n","\n","                               Conference  Playoffs  dffPTS  SeasonEnd  \\\n","Team                SeasonEnd                                            \n","Philadelphia 76ers  2014                0         0    -857       2014   \n","Detroit Pistons     2004                0         1     479       2004   \n","San Antonio Spurs   2004                1         1     592       2004   \n","Indiana Pacers      2004                0         1     472       2004   \n","Cleveland Cavaliers 1997                0         0     151       1997   \n","...                                   ...       ...     ...        ...   \n","Denver Nuggets      1981                1         0     -39       1981   \n","                    1983                1         0      51       1983   \n","                    1984                1         0     -90       1984   \n","                    1982                1         1      43       1982   \n","                    1991                1         0    -895       1991   \n","\n","                               NextYearPlayoffs  \n","Team                SeasonEnd                    \n","Philadelphia 76ers  2014                      0  \n","Detroit Pistons     2004                      1  \n","San Antonio Spurs   2004                      1  \n","Indiana Pacers      2004                      1  \n","Cleveland Cavaliers 1997                      1  \n","...                                         ...  \n","Denver Nuggets      1981                      1  \n","                    1983                      0  \n","                    1984                      1  \n","                    1982                      0  \n","                    1991                      0  \n","\n","[858 rows x 22 columns]"],"text/html":["\n","  <div id=\"df-6f94fcc5-3b51-4abf-a73a-3e9f8dfd7c96\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th></th>\n","      <th>W</th>\n","      <th>PTS</th>\n","      <th>oppPTS</th>\n","      <th>FG</th>\n","      <th>FGA</th>\n","      <th>2P</th>\n","      <th>2PA</th>\n","      <th>3P</th>\n","      <th>3PA</th>\n","      <th>FT</th>\n","      <th>...</th>\n","      <th>DRB</th>\n","      <th>AST</th>\n","      <th>STL</th>\n","      <th>BLK</th>\n","      <th>TOV</th>\n","      <th>Conference</th>\n","      <th>Playoffs</th>\n","      <th>dffPTS</th>\n","      <th>SeasonEnd</th>\n","      <th>NextYearPlayoffs</th>\n","    </tr>\n","    <tr>\n","      <th>Team</th>\n","      <th>SeasonEnd</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Philadelphia 76ers</th>\n","      <th>2014</th>\n","      <td>19</td>\n","      <td>8155</td>\n","      <td>9012</td>\n","      <td>3108</td>\n","      <td>7150</td>\n","      <td>2531</td>\n","      <td>5303</td>\n","      <td>577</td>\n","      <td>1847</td>\n","      <td>1362</td>\n","      <td>...</td>\n","      <td>2556</td>\n","      <td>1791</td>\n","      <td>765</td>\n","      <td>330</td>\n","      <td>1384</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>-857</td>\n","      <td>2014</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Detroit Pistons</th>\n","      <th>2004</th>\n","      <td>54</td>\n","      <td>7388</td>\n","      <td>6909</td>\n","      <td>2747</td>\n","      <td>6314</td>\n","      <td>2414</td>\n","      <td>5346</td>\n","      <td>333</td>\n","      <td>968</td>\n","      <td>1561</td>\n","      <td>...</td>\n","      <td>2492</td>\n","      <td>1702</td>\n","      <td>659</td>\n","      <td>570</td>\n","      <td>1241</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>479</td>\n","      <td>2004</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>San Antonio Spurs</th>\n","      <th>2004</th>\n","      <td>57</td>\n","      <td>7501</td>\n","      <td>6909</td>\n","      <td>2842</td>\n","      <td>6434</td>\n","      <td>2434</td>\n","      <td>5294</td>\n","      <td>408</td>\n","      <td>1140</td>\n","      <td>1409</td>\n","      <td>...</td>\n","      <td>2669</td>\n","      <td>1676</td>\n","      <td>661</td>\n","      <td>537</td>\n","      <td>1203</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>592</td>\n","      <td>2004</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>Indiana Pacers</th>\n","      <th>2004</th>\n","      <td>61</td>\n","      <td>7493</td>\n","      <td>7021</td>\n","      <td>2753</td>\n","      <td>6322</td>\n","      <td>2304</td>\n","      <td>5041</td>\n","      <td>449</td>\n","      <td>1281</td>\n","      <td>1538</td>\n","      <td>...</td>\n","      <td>2452</td>\n","      <td>1774</td>\n","      <td>726</td>\n","      <td>411</td>\n","      <td>1182</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>472</td>\n","      <td>2004</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>Cleveland Cavaliers</th>\n","      <th>1997</th>\n","      <td>42</td>\n","      <td>7173</td>\n","      <td>7022</td>\n","      <td>2704</td>\n","      <td>5972</td>\n","      <td>2221</td>\n","      <td>4688</td>\n","      <td>483</td>\n","      <td>1284</td>\n","      <td>1282</td>\n","      <td>...</td>\n","      <td>2159</td>\n","      <td>1714</td>\n","      <td>655</td>\n","      <td>315</td>\n","      <td>1188</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>151</td>\n","      <td>1997</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"5\" valign=\"top\">Denver Nuggets</th>\n","      <th>1981</th>\n","      <td>37</td>\n","      <td>9986</td>\n","      <td>10025</td>\n","      <td>3784</td>\n","      <td>7960</td>\n","      <td>3754</td>\n","      <td>7815</td>\n","      <td>30</td>\n","      <td>145</td>\n","      <td>2388</td>\n","      <td>...</td>\n","      <td>2497</td>\n","      <td>2030</td>\n","      <td>720</td>\n","      <td>380</td>\n","      <td>1444</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>-39</td>\n","      <td>1981</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1983</th>\n","      <td>45</td>\n","      <td>10105</td>\n","      <td>10054</td>\n","      <td>3951</td>\n","      <td>7999</td>\n","      <td>3927</td>\n","      <td>7873</td>\n","      <td>24</td>\n","      <td>126</td>\n","      <td>2179</td>\n","      <td>...</td>\n","      <td>2524</td>\n","      <td>2336</td>\n","      <td>789</td>\n","      <td>352</td>\n","      <td>1496</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>51</td>\n","      <td>1983</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1984</th>\n","      <td>38</td>\n","      <td>10147</td>\n","      <td>10237</td>\n","      <td>3935</td>\n","      <td>7983</td>\n","      <td>3858</td>\n","      <td>7728</td>\n","      <td>77</td>\n","      <td>255</td>\n","      <td>2200</td>\n","      <td>...</td>\n","      <td>2444</td>\n","      <td>2482</td>\n","      <td>711</td>\n","      <td>352</td>\n","      <td>1344</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>-90</td>\n","      <td>1984</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1982</th>\n","      <td>46</td>\n","      <td>10371</td>\n","      <td>10328</td>\n","      <td>3980</td>\n","      <td>7656</td>\n","      <td>3940</td>\n","      <td>7507</td>\n","      <td>40</td>\n","      <td>149</td>\n","      <td>2371</td>\n","      <td>...</td>\n","      <td>2443</td>\n","      <td>2272</td>\n","      <td>664</td>\n","      <td>368</td>\n","      <td>1470</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>43</td>\n","      <td>1982</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1991</th>\n","      <td>20</td>\n","      <td>9828</td>\n","      <td>10723</td>\n","      <td>3901</td>\n","      <td>8868</td>\n","      <td>3601</td>\n","      <td>7809</td>\n","      <td>300</td>\n","      <td>1059</td>\n","      <td>1726</td>\n","      <td>...</td>\n","      <td>2530</td>\n","      <td>2005</td>\n","      <td>856</td>\n","      <td>406</td>\n","      <td>1332</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>-895</td>\n","      <td>1991</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>858 rows Ã— 22 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6f94fcc5-3b51-4abf-a73a-3e9f8dfd7c96')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-6f94fcc5-3b51-4abf-a73a-3e9f8dfd7c96 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-6f94fcc5-3b51-4abf-a73a-3e9f8dfd7c96');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"_g36DLvvQC4v"},"source":["# Split the data into training and testing sets\n","df_train = df_nextyear[df_nextyear.SeasonEnd<2012]\n","df_test = df_nextyear[df_nextyear.SeasonEnd>=2012]\n","\n","# Write your code here.\n","\n","# -------------------\n","\n","drop_for_X = ['SeasonEnd', 'NextYearPlayoffs']\n","\n","X_train = df_train.drop(columns=drop_for_X)\n","y_train = df_train.NextYearPlayoffs\n","\n","# logreg = LogisticRegression()\n","# logreg.fit(X_train, y_train)\n","\n","X_test = df_test.drop(columns=drop_for_X)\n","y_test = df_test.NextYearPlayoffs\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CZPRktKl2o_s"},"source":["## Addressing a warning message\n","You should see a message about a `ConvergenceWarning` that explains that the solver (i.e., the optimizer that \"finds\" the coefficients for the model) failed to converge before hitting the iteration limit. This limit is set by the `max_iter` parameter, and by default it is limited to 100 iteration.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"C1vmR6x3Lp53"},"source":["### Exercise\n","1. Make a new model called `logreg_max_iter_5000` by training the model from the code block above for a maximum of 5000 iterations. \n","\n","2. Use the `score` method for logistic regression to evaluate the mean accuracy of `logreg` and `logreg_max_iter_5000`. What model performed best? \n","\n"]},{"cell_type":"code","metadata":{"id":"6L_JkBlu62qA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664126966876,"user_tz":240,"elapsed":321,"user":{"displayName":"Zhuolun Du","userId":"16686697190012944947"}},"outputId":"d2368b32-acc6-4dd0-bc12-b9bee92ee136"},"source":["### Question 1\n","\n","# -------------------\n","\n","logreg_max_iter_5000 = LogisticRegression(max_iter=5000)\n","logreg_max_iter_5000.fit(X_train, y_train)\n","\n","# -------------------"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["LogisticRegression(max_iter=5000)"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","metadata":{"id":"K0c92XD_2nQ6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663105605857,"user_tz":240,"elapsed":7,"user":{"displayName":"Craig Fer","userId":"10199331155832657902"}},"outputId":"c5d138d0-930c-4808-d147-2ac94352790a"},"source":["### Question 2\n","\n","# -------------------\n","\n","\n","\n","# -------------------"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["With default parameters: \n","\t Train score 0.747\n","\t Test score 0.644\n","With max_iters = 5000: \n","\t Train score 0.749\n","\t Test score 0.644\n"]}]},{"cell_type":"code","source":["train_score = logreg_max_iter_5000.score(X_train, y_train)\n","test_score = logreg_max_iter_5000.score(X_test, y_test)\n","print('The train score is {} and the test score is {}'.format(train_score, test_score))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xbu2Jxt4sp-2","executionInfo":{"status":"ok","timestamp":1664127033105,"user_tz":240,"elapsed":295,"user":{"displayName":"Zhuolun Du","userId":"16686697190012944947"}},"outputId":"8cd66cd5-29b3-435f-821e-62ec4fa9f09d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The train score is 0.7486979166666666 and the test score is 0.6444444444444445\n"]}]},{"cell_type":"markdown","metadata":{"id":"m3nkZlRHdWs6"},"source":["By addressing that warning messages we managed to get a slight improvement in training scores but the same performance for test scores.\n","\n","If you reviewed the  `LogisticRegression` documentation, you may have noticed that the the `fit` method uses L2-regularization by default. Also recall (from the linear regression section) that the features of this model are highly correlated with each other, which is problematic. \n","\n","Let's try using L1-regularization by setting the `penalty` parameter of `LogisticRegression` to 'l1'. We also need to set the solver to 'saga' because the default solver of `LogisticRegression` does not work with L1 regularization. We still need `max_iter` of 5000:"]},{"cell_type":"code","metadata":{"id":"W4BXvqiMd-cB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664127064063,"user_tz":240,"elapsed":748,"user":{"displayName":"Zhuolun Du","userId":"16686697190012944947"}},"outputId":"3bd1656b-ab4b-40b5-f865-3e9dc5ddef78"},"source":["# Fit the model\n","logregl1 = LogisticRegression(penalty='l1', solver='saga', max_iter=5000)\n","logregl1.fit(X_train, y_train)\n","\n","# calculate the score\n","train_score = logregl1.score(X_train, y_train)\n","test_score = logregl1.score(X_test, y_test)\n","print(f'The train score is {train_score:.3} and the test score is {test_score:.3}')\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The train score is 0.747 and the test score is 0.644\n"]}]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"R9tvHY5uWv8u"},"source":["## Using cross validation to select regularizer\n","You should see that the L2 regularized model performed essentially the same as the L1 regularized model. However, before we make any conclusions about which regularizer is better suited for this problem, it is important to recognize that we did not perform cross-validation to optimize for the strength of the regularizer.\n"]},{"cell_type":"markdown","metadata":{"id":"w_xR1fhILsZN"},"source":["\n","### Exercise\n","1. Use the [`LogisticRegressionCV()`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegressionCV.html) to fit a model that uses cross-validation and choose the best regularizer strength. Use L1 penalty, saga solver and max_iter of 5000. Call your model `logregcv`. What is the train and test score? After you build your model, we provide the code to print the Beta coefficients (as this may be useful for your reports).\n","\n","2. What is the optimal regularization strength? Check the documentation to find what variable it is listed under."]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"lr2xqV5IWv8v","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664127449790,"user_tz":240,"elapsed":4541,"user":{"displayName":"Zhuolun Du","userId":"16686697190012944947"}},"outputId":"981133e4-35d7-4fe5-f11f-33409cff14ce"},"source":["# Question 1\n","# Write your code here.\n","# -------------------\n","\n","\n","logregcv = LogisticRegressionCV(penalty='l1', solver='saga', max_iter=5000)\n","logregcv.fit(X_train, y_train)\n","\n","train_score = logregcv.score(X_train, y_train)\n","test_score = logregcv.score(X_test, y_test)\n","print(f'The train score is {train_score:.3} and the test score is {test_score:.3}')\n","\n","\n","# -------------------\n","\n","# Get beta coefficients\n","betas = pd.Series(logregcv.coef_[0], index=X_train.columns)\n","# Get intercept, and append it to coefficients\n","betas = betas.append(pd.Series({\"Intercept\": logregcv.intercept_[0]}))\n","# Print the all betas (including the intercept)\n","print('\\n', betas)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The train score is 0.749 and the test score is 0.689\n","\n"," W             0.000000e+00\n","PTS           1.140885e-05\n","oppPTS        0.000000e+00\n","FG            0.000000e+00\n","FGA           0.000000e+00\n","2P            0.000000e+00\n","2PA           0.000000e+00\n","3P            0.000000e+00\n","3PA           0.000000e+00\n","FT            0.000000e+00\n","FTA           0.000000e+00\n","ORB           0.000000e+00\n","DRB           0.000000e+00\n","AST           0.000000e+00\n","STL           0.000000e+00\n","BLK           0.000000e+00\n","TOV           0.000000e+00\n","Conference    0.000000e+00\n","Playoffs      0.000000e+00\n","dffPTS        3.252508e-03\n","Intercept     5.133107e-07\n","dtype: float64\n"]}]},{"cell_type":"code","source":["1/logregcv.C_[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a2xpNaLaueoR","executionInfo":{"status":"ok","timestamp":1664127591127,"user_tz":240,"elapsed":318,"user":{"displayName":"Zhuolun Du","userId":"16686697190012944947"}},"outputId":"3455d54d-443a-44d9-bbda-006a3af75430"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["10000.0"]},"metadata":{},"execution_count":40}]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"QRuIk-nsWv8w","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663105612173,"user_tz":240,"elapsed":8,"user":{"displayName":"Craig Fer","userId":"10199331155832657902"}},"outputId":"eaec7ccc-c3e4-4618-f582-47a6e34652c5"},"source":["# Question 2\n","\n","# -------------------\n","\n","\n","# -------------------"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The strength of the regularier is 10000.0\n"]}]},{"cell_type":"markdown","metadata":{"id":"c4HBXpmlSibi"},"source":["### Exercise \n","To answer the next question, you may find the [`predict()`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.predict), [`predict_proba()`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.predict_proba), and [`predict_log_proba()`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.predict_log_proba) methods useful.\n","\n","1. Suppose that the Toronto Raptors have the statistics stored in `raptors_2021` (i.e., the stats for the 2020-2021 season). What is the probability that the raptors make the playoffs in the 2021-2022 season?\n","\n"]},{"cell_type":"code","metadata":{"id":"0gjKj2MjKDCI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664130515725,"user_tz":240,"elapsed":5,"user":{"displayName":"Zhuolun Du","userId":"16686697190012944947"}},"outputId":"62a86112-1a62-4f38-9f6d-50a149ad37cb"},"source":["### Question 1\n","\n","raptors_2021 = pd.DataFrame([{'W':47, 'PTS': 10105, 'oppPTS': 10054, 'FG': 3951, \n","                           'FGA':7999, '2P': 3927, '2PA': 7873, '3P': 24,\n","                           \"3PA\": 126, 'FT': 2179, 'FTA': 2696, 'ORB':1214,\n","                           'DRB': 2524, 'AST': 2336, 'STL': 789, 'BLK': 352,\n","                           'TOV': 1496, 'Conference': 0,'Playoffs':1, 'dffPTS': 51}])\n","\n","# Write your code here.\n","\n","# -------------------\n","logregcv.predict_proba(raptors_2021)[0,1]\n","\n","# -------------------"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.5698317753089055"]},"metadata":{},"execution_count":46}]},{"cell_type":"markdown","metadata":{"id":"Jb9lXBv-eyze"},"source":["## Classification Error\n","\n","So far, we have only evaluated the model performance based on accuracy, however, it is also good to know what type of errors the model is susceptible to. Scikit-learn provides an easy way to do this via the `confusion_matrix()` function."]},{"cell_type":"code","metadata":{"id":"FCKI3Uo5WfBu","colab":{"base_uri":"https://localhost:8080/","height":279},"executionInfo":{"status":"ok","timestamp":1664130684733,"user_tz":240,"elapsed":1125,"user":{"displayName":"Zhuolun Du","userId":"16686697190012944947"}},"outputId":"e89b458c-612b-4933-c7b3-6b72a9636514"},"source":["# Make a prediction\n","y_pred = logregcv.predict(X_test)\n","# Make the confusion matrix\n","cfm = confusion_matrix(y_true=y_test, y_pred=y_pred)\n","# Plot the confusion matrix as a heat map\n","ax = sns.heatmap(cfm, annot=True)\n","# Change the axis lables\n","ax.set(xlabel='Predicted', ylabel='Actual');"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 2 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"9RegV0pssHbB"},"source":["### Exercise\n","Use the Confusion matrix above to answer the following questions.\n","\n","1. What is the number of true positives? True negatives?\n","2. What is the largest type of error that the model makes?\n","3. Calculate the recall and precision. \n"]},{"cell_type":"code","metadata":{"id":"in-jX0u6Wgx0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663105612475,"user_tz":240,"elapsed":13,"user":{"displayName":"Craig Fer","userId":"10199331155832657902"}},"outputId":"028e4cc6-e11f-4728-8a20-0a8f35b09006"},"source":["### Question 1\n","\n","# Write your code here.\n","\n","# -------------------\n","\n","\n","\n","# -------------------"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["There are 28 true negatives and 34 true positives\n"]}]},{"cell_type":"markdown","metadata":{"id":"xP3g3SnWs4xd"},"source":["\n","___\n","**Question 2 answer:** False positives\n","___\n","\n"]},{"cell_type":"code","metadata":{"id":"xqfGd9Ozcj2o","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663105612475,"user_tz":240,"elapsed":11,"user":{"displayName":"Craig Fer","userId":"10199331155832657902"}},"outputId":"e09ad717-8d69-4812-859c-285cd7c1f4cb"},"source":["### Question 3\n","\n","# Write your code here.\n","\n","# -------------------\n","\n","\n","\n","# -------------------"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The recall is 0.7391304347826086 and the precision is 0.68\n"]}]},{"cell_type":"code","source":["recall = cfm[1,1] / (cfm[1,0] + cfm[1,1])\n","precision = cfm[1, 1] / (cfm[0, 1] + cfm[1, 1])\n","print('The recall is {} and the precision is {}'.format(recall, precision))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jh23eZSi7DzS","executionInfo":{"status":"ok","timestamp":1664130769914,"user_tz":240,"elapsed":5,"user":{"displayName":"Zhuolun Du","userId":"16686697190012944947"}},"outputId":"f5f3d029-5133-4fe1-f5d2-7fc963d73eb5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The recall is 0.7391304347826086 and the precision is 0.68\n"]}]},{"cell_type":"markdown","metadata":{"id":"UfDhUZcqIfWb"},"source":["## Picking a prediction threshold\n","Recall that a logistic regression model outputs the probability of whether the the target is 1 or 0. We then apply a threshold rule to turn that probability into a prediction. The default threshold in scikit-learn is 0.5, but it is a good idea to examine the raw probabilities to see if a better threshold exists.\n","\n","The tool that is most used to help choose a threshold is a receiver operating characteristic (ROC) curve. The ROC curve is a plot of true positive rate (TPR) versus false positive rate (FPR) for different threshold values. It is used in a lot in applications where it is important to make sure that there are very few false positives (i.e., false alarms) or very few false negatives (i.e., missed detections).\n","\n","In this section you will plot ROC curves for the three logistic regression models that we built (i.e., `logreg`, `logregl1`, `logregcv`). The [`roc_curve()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html) function in `sklearn` makes it easy to generate the data for an ROC curve plot. As input, this function takes the ground truth target label and the model's estimated probability of \"1\", which is generated by the [`predict_proba()`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.predict_proba) method. As output, `roc_curve()` returns the FPR, TPR, and the threshold to achieve those statistics.\n"]},{"cell_type":"markdown","metadata":{"id":"G8UViU-pyvMx"},"source":["### Exercise\n","\n","1. Plot FPR and TPR using [`sns.lineplot()`](https://seaborn.pydata.org/generated/seaborn.lineplot.html) to generate an ROC curve for each of the three models (i.e., `logreg`, `logregl1`, `logregcv`). We have provided some of the code to format the resulting plot.\n","\n","2. What does the straight line from (0,0) to (1,1) represent?\n","\n","3. According to the `roc_curve()` function, what is the highest threshold value at which you should get a TPR=1 for your L1-cross-validated model?\n","\n","4. Is there any scenario where the cross-validated model is worse than any of the other models?\n"]},{"cell_type":"code","metadata":{"id":"sKQ58mHkumIV","colab":{"base_uri":"https://localhost:8080/","height":405},"executionInfo":{"status":"ok","timestamp":1664132332470,"user_tz":240,"elapsed":4426,"user":{"displayName":"Zhuolun Du","userId":"16686697190012944947"}},"outputId":"5b55b0a9-5221-4b31-ca99-6e597439d7ba"},"source":["from sklearn.metrics import roc_curve\n","\n","# Write your code here.\n","\n","# -------------------\n","\n","ylogreg = logreg.predict_proba(X_test).T[1]\n","fprlogreg, tprlogreg, threshlogreg = roc_curve(y_test, ylogreg)\n","\n","ylogregl1 = logregl1.predict_proba(X_test).T[1]\n","fprlogregl1, tprlogregl1, threshlogregl1 = roc_curve(y_test, ylogregl1)\n","\n","ylogregcv = logregcv.predict_proba(X_test).T[1]\n","fprlogregcv, tprlogregcv, threshlogregcv = roc_curve(y_test, ylogregcv)\n","\n","sns.lineplot(fprlogreg, tprlogreg, label='Original')\n","sns.lineplot(fprlogregl1, tprlogregl1, label='L1')\n","sns.lineplot(fprlogregcv, tprlogregcv, label='L1-CV')\n","\n","# -------------------\n","\n","# Plot format\n","sns.lineplot(x=[0, 1], y=[0, 1], linestyle='--')  # add red line\n","plt.xlim([0.0, 1.0])  # limit x-axis between 0 and 1\n","plt.ylim([0.0, 1.0])  # limit y-axis between 0 and 1\n","plt.xlabel('False Positive Rate')  # lable for x axis\n","plt.ylabel('True Positive Rate')  # lable for y axis\n","plt.legend(loc='lower right')  # print legend in lower right corner\n","plt.show()  "],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","  FutureWarning\n","/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","  FutureWarning\n","/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","  FutureWarning\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"IEulLyjMvciD"},"source":["___\n","**Question 2 answer:**\n","\n","\n","___"]},{"cell_type":"code","metadata":{"id":"tbFCuPtFwOcp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663105615263,"user_tz":240,"elapsed":6,"user":{"displayName":"Craig Fer","userId":"10199331155832657902"}},"outputId":"cb2ac1d0-bb4d-4609-e60d-16d306b97d4b"},"source":["# Question 3\n","\n","# Write your code here.\n","\n","# -------------------\n","\n","\n","# -------------------"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The highest threshold that achieves at least 90% TPR is 0.313\n"]}]},{"cell_type":"code","source":["np.round(np.array([fprlogregcv, tprlogregcv, threshlogregcv]).T,3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_I5u1fpiB7tu","executionInfo":{"status":"ok","timestamp":1664132571437,"user_tz":240,"elapsed":409,"user":{"displayName":"Zhuolun Du","userId":"16686697190012944947"}},"outputId":"6fe8514d-7a5f-425f-e006-a79b50d0eb8c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.   , 0.   , 1.942],\n","       [0.   , 0.022, 0.942],\n","       [0.   , 0.174, 0.859],\n","       [0.023, 0.174, 0.857],\n","       [0.023, 0.217, 0.824],\n","       [0.045, 0.217, 0.811],\n","       [0.045, 0.239, 0.799],\n","       [0.068, 0.239, 0.796],\n","       [0.068, 0.283, 0.784],\n","       [0.091, 0.283, 0.78 ],\n","       [0.091, 0.304, 0.773],\n","       [0.114, 0.304, 0.772],\n","       [0.114, 0.478, 0.714],\n","       [0.136, 0.478, 0.71 ],\n","       [0.136, 0.5  , 0.705],\n","       [0.182, 0.5  , 0.69 ],\n","       [0.182, 0.63 , 0.606],\n","       [0.205, 0.63 , 0.6  ],\n","       [0.205, 0.652, 0.582],\n","       [0.273, 0.652, 0.551],\n","       [0.273, 0.717, 0.541],\n","       [0.295, 0.717, 0.537],\n","       [0.295, 0.739, 0.534],\n","       [0.364, 0.739, 0.508],\n","       [0.364, 0.783, 0.484],\n","       [0.432, 0.783, 0.456],\n","       [0.432, 0.826, 0.425],\n","       [0.5  , 0.826, 0.368],\n","       [0.5  , 0.87 , 0.353],\n","       [0.568, 0.87 , 0.336],\n","       [0.568, 0.935, 0.313],\n","       [0.705, 0.935, 0.274],\n","       [0.705, 0.957, 0.25 ],\n","       [0.909, 0.957, 0.139],\n","       [0.909, 0.978, 0.11 ],\n","       [0.955, 0.978, 0.09 ],\n","       [0.955, 1.   , 0.085],\n","       [1.   , 1.   , 0.063]])"]},"metadata":{},"execution_count":51}]},{"cell_type":"markdown","metadata":{"id":"L9IrUcxp0rca"},"source":["___\n","**Question 4 answer**:\n","\n","___"]},{"cell_type":"markdown","metadata":{"id":"vfp-CzkCkBvp"},"source":["# Learning Check Point\n","\n","In the second half of the lab, we learned about logistic regression. We also explored cross validation to choose the best regularizer strength. We discuss different types of classification error and how to pick the best threshold value (which can be visualized through ROC curves).\n"]},{"cell_type":"markdown","metadata":{"id":"8cacqc_P3XUd"},"source":["# Reflection Exercise\n","1. In what ways are the first set of linear regression models useful (i.e., understanding wins based on this season's data), and in what ways are the logistic regresion models useful (i.e., predicting playoffs based off last season's data)?"]},{"cell_type":"markdown","metadata":{"id":"-OVYrQ8UU8fR"},"source":["___\n","**Question 1 answer:**\n","\n","___\n"]}]}