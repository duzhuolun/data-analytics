{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.2"},"colab":{"provenance":[{"file_id":"13W4_4FWIpprPYFAHziBe6glaSxan4Xy9","timestamp":1663173180350}],"collapsed_sections":[]},"pycharm":{"stem_cell":{"cell_type":"raw","source":[],"metadata":{"collapsed":false}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"qJO6wLqtku-o"},"source":["<center>\n","    <h3>University of Toronto</h3>\n","    <h3>Department of Mechanical and Industrial Engineering</h3>\n","    <h3>MIE368 Analytics in Action </h3>\n","    <h3>(Fall 2022)</h3>\n","    <hr>\n","    <h1>Lab 3`: Classification and Regression Trees (CART) and Random Forest</h1>\n","    <h3>September 28, 2022</h3>\n","</center>\n"]},{"cell_type":"markdown","metadata":{"id":"BgIYDa5lku-p"},"source":["# Introduction\n","In this lab we investigate the use of classification and regression trees (CART) and random forests. Unlike linear and logistic regression, these methods do not make any assumptions about the target variable being linearly dependent on the independent feature variables. Instead, they are data-driven and use a number of logical rules to classify observations and make associated predictions. CART and random forests can be used to predict both continuous and discrete (categorical) targets.\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"SPG_vr_iM1gS"},"source":["## Background and Methods\n","In this section we provide a high-level description of the methods studied within this lab, namely CART and random forests. These methods are forms of decision tree learning where sample observation characteristics are mapped to conclusions about the sample observation’s target value (i.e., the prediction). The main difference between the two methods is that CART uses a single decision tree while random forests use multiple trees, as discussed in subsequent sections."]},{"cell_type":"markdown","metadata":{"id":"735d7weSlayD"},"source":["## Classification and Regression Trees (CART) Information\n","These models consist of a single decision tree that looks to capture non-linearities between the input features and the output target. A major advantage that CART models have over other classification models such as logistic regression, is their interpretability. While logistic regression is useful in describing the likelihood of an event to be predicted, a CART model can procedurally show exactly what each feature needs to be in order to yield a given event.\n","\n","If we recall from lecture, CART was presented in the context of the American Supreme Court, where we looked to predict whether the Supreme Court judges (Justices) would affirm (uphold) or reverse (overturn) lower court decisions. Model predictions were made based on six feature variables with associated binary (yes/no) responses. These variables include responses to questions such as: i) Is the lower court decision liberal? ii) Is the case from District _A_?. In this particular application, the interpretability of a specific prediction is highly valued.\n","\n","Figure 1 illustrates a CART for a colour prediction problem with two feature variables and two output classes (i.e., red or gray). To build a CART model we _split_ on the selected feature variables (in some particular order), producing child nodes from each parent node. Each split is based on a single independent feature variable. For the model illustrated in Figure 1, our first split uses the question \"is $X < 60$?\", which produces a binary yes/no response. If the response is _yes_ then we classify the observation as red immediately, however, if the response is _no_, deeper nodes within the tree must be explored. \n","\n","<img src=\"https://docs.google.com/uc?export=view&id=1uWGSkB2AlAx0DcyS_9DgO-YJeQNsPZKu\" \n","alt=\"\"/>\n","\n","Figure 1: Classification and regression tree (CART) with two feature variables.\n","\n","A prediction (classification) of the observation is made whenever a leaf node (i.e., a node with no children) is reached within the decision tree. At such leaves the percentage of observations in a given group (e.g., red or gray) is calculated and a threshold is applied to make a prediction. The splits within a CART are selected to produce the most _pure_ children (i.e., the cleanest separation of the classes). In this example there are only two classes, however, CART can be used for multi-class problems as well as continuous problems.\n","\n","There are a number of choices to make when designing and training a specific CART model, including:\n","\n","- Which feature variable should we split on? When? Some relevant metrics for answering these questions are Gini and Entropy measures.\n","- How many splits are generated within our CART? For example, you could try constraining the number of splits generated using lower/upper bounds.\n","\n","Such parameter selection for the design of CART models is crucial to the performance of the model. In general, we try to select parameter values that produce good results. Though it may be tempting, choosing the parameters that yield the highest prediction accuracy is not necessarily the way to go due to overfitting. As discussed in previous labs, techniques such as m-Fold Cross Validation can ensure our parameters will perform best on various input observation sets, thus avoiding this issue.\n"]},{"cell_type":"markdown","metadata":{"id":"2lf_sxK0tq6m"},"source":["### Exercise\n","\n","Answer the following review questions related to CART:\n","1. Would a statistically insignificant variable be useful to split on in a CART model?"]},{"cell_type":"markdown","metadata":{"id":"lI1P3Hb8ku-s"},"source":["  ___\n"," __Question 1 Answer__:\n","\n","___"]},{"cell_type":"markdown","metadata":{"id":"7IrmC2hlku-t"},"source":["2. Should we always select the CART design parameters that maximize accuracy on the test set?"]},{"cell_type":"markdown","metadata":{"id":"dsKEH-SNku-v"},"source":["___\n","__Question 2 Answer__:\n","\n","___"]},{"cell_type":"markdown","metadata":{"id":"Hxn2Pp8oku-w"},"source":["3. True/False: CART models can only be used for problems with two prediction classes"]},{"cell_type":"markdown","metadata":{"id":"kbKMbB1-ku-w"},"source":["___\n","__Question 3 Answer__:\n","\n","___"]},{"cell_type":"markdown","metadata":{"id":"1MNMelFwku-x"},"source":["## Random Forests Information\n","\n","This approach was designed primarily as a way to boost the performance of CART. Random forests are a form of ensemble method that combines predictions from multiple models to attain a better overall performance than each of the individual underlying models. Specifically, random forests combine a large number of CART trees, each of which ‘vote’ on the outcome, to deduce a final prediction. Although there are a large number of voting rules that could be used, a simple and common one for classification is a _majority rule_, which states that if most of the trees in a forest give a certain prediction, then the forest gives that same prediction. A similarly simple rule for regression ensembles is an average rule.\n","\n","Random forests are formed by running CART on a subset of the observations (from the total training set) and a subset of feature variables (from the total feature variable set). Note, it is common practice to use a subset of observations, but it is not strictly required. The process of creating a subset of observations used in random forest (and other ensemble methods) is termed *bootstrap aggregating*, or *bagging*, (the term bagging is derived as a short form of **b**ootstrap **agg**regat**ing**). \n","\n","Within the bootstrap aggregating (bagging) approach, we create multiple *bootstrapped* samples of the dataset. Each bootstrapped sample has size $m$ and does not have to be the same size of the full dataset, $n$. When creating each bootstrapped sample, we sample with replacement from the full dataset, meaning we could have duplicate rows from the original dataset in our bootstrapped sample. For example, two valid bootstrapped samples of the dataset {$1,2,3,4,5$} could be {$1,3,4$} and {$2,5,2$}, as they contain only elements from the original data set, and both samples are the same size ($m=3$).\n","\n","To summarize, *Bootstrapping* is a sampling technique and *Bagging* is a machine learning ensemble model that is built using bootstrapped samples.\n","\n","As covered in CART, there are a number of parameter design decisions to make for a specific random forest model (independent of the underlying CART design):\n","\n"," - The number of CART trees to build (typically set to the order of $10^2$)\n"," - More trees can result in longer computation times, but typically stronger performance (i.e., tradeoff in construction time and prediction performance)\n"," \n","These parameter choices are in addition to those selected for CART design (e.g., size of each individual trees). Due to their ensemble nature, random forests are less sensitive to model parameters, however, how they arrive at their predictions is effectively impossible to inteprete (making it a _black box_). As a black box, a random forest is likely not suitable for the Supreme Court example covered in lecture. \n","\n"]},{"cell_type":"markdown","metadata":{"id":"9qqiaUCZueRa"},"source":["### Exercise\n","\n","Answer the following questions related to random forest:\n","1. Could you combine a CART tree and a logistic regression as an ensemble method? Why/why not?"]},{"cell_type":"markdown","metadata":{"id":"tR4BHb7pku-y"},"source":["___\n","__Question 1 Answer__:\n","\n","___"]},{"cell_type":"markdown","metadata":{"id":"fYvcAKqYku-z"},"source":["2. What would a potential bootstrapped sample of the dataset {1,2,3,4,5,6} be?"]},{"cell_type":"markdown","metadata":{"id":"dMXpo_aRku-0"},"source":["___\n","__Question 2 Answer__:\n","\n","___"]},{"cell_type":"markdown","metadata":{"id":"ynciyPANku-2"},"source":["3. True/False: The predictions of a random forest are more easily interpreted than those of a single CART tree."]},{"cell_type":"markdown","metadata":{"id":"Fp7vpjJfku-3"},"source":["___\n","__Question 3 Answer__:\n","\n","___\n"]},{"cell_type":"markdown","metadata":{"id":"UtZtfRO0ku-4"},"source":["# Application\n","In this lab, we investigate vandalism in Wikipedia (en.wikipedia.org). Wikipedia is the world’s largest free online encyclopedia, containing in the neighbourhood of 5.8 million articles with roughly 156,000 edits per day. Wikipedia allows anyone to contribute/edit entries, which promotes rapid content creation and community-based error checking. An unfortunate side effect of this approach is the presence of vandalism. Specifically, we refer to pages that have had information removed, incorrect information added, or the presence of inappropriate content. Due to the volume of entries being changed on a daily basis, it is incredibly difficult to manually (i.e., human checking) ensure the accuracy of pages and remove any instances of vandalism.\n","\n","In this lab, we will look at a dataset that summarizes the revision history for the [“Language” entry on Wikipedia](https://en.wikipedia.org/wiki/Language). We will conduct some exploratory data analysis (EDA) and look into predicting whether a particular revision was an instance of vandalism or not. For this application, an accurately performing model can be very useful - the free and accurate flow of world information depends on it! Please answer the questions wherever a blank is provided, and discuss answers with your peers.\n","\n","The following sections detail the main steps associated with this lab. First, we will start by understanding decision trees (CART) a little better through the use of a written example. Next, we use `sklearn` to explore the data and build CART trees and random forests for the full Wikipedia dataset. Let’s get started! As usual we will load the necessary packages and load the dataset."]},{"cell_type":"code","metadata":{"id":"j7Lp6oiaku-5","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1664804586166,"user_tz":240,"elapsed":3191,"user":{"displayName":"Zhuolun Du","userId":"16686697190012944947"}},"outputId":"c9a46ed0-04c8-42cb-bf4d-1d301b2f1c1e"},"source":["# Import packagesimport matplotlib.pyplot as plt\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","from sklearn.model_selection import train_test_split\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.tree import export_graphviz\n","from IPython.display import SVG\n","from graphviz import Source\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import cross_validate\n","from sklearn.linear_model import LogisticRegressionCV\n","\n","\n","# Load dataset\n","df = pd.read_csv('https://docs.google.com/uc?export=download&id=1zIXF6ReaoqdglnMsQf5u6zQdfEvu8paT') \n","df.head() # prints the first 5 rows of the dataframe "],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["  Vandal Minor LoggedIn HTTP NumWordsAdded NumWordsRemoved\n","0      0     1        1    1            96               0\n","1      0     1        1    0             3               1\n","2      0     0        1    0             0               4\n","3      0     1        0    0            10              92\n","4      0     1        1    1            94              10"],"text/html":["\n","  <div id=\"df-c295b7a6-fd4d-4cf0-8054-8ac9da75d765\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Vandal</th>\n","      <th>Minor</th>\n","      <th>LoggedIn</th>\n","      <th>HTTP</th>\n","      <th>NumWordsAdded</th>\n","      <th>NumWordsRemoved</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>96</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10</td>\n","      <td>92</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>94</td>\n","      <td>10</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c295b7a6-fd4d-4cf0-8054-8ac9da75d765')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c295b7a6-fd4d-4cf0-8054-8ac9da75d765 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c295b7a6-fd4d-4cf0-8054-8ac9da75d765');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":1}]},{"cell_type":"markdown","metadata":{"id":"kSDeVuBpku_A"},"source":["The table below contains the data dictionary.\n","\n","|Feature          |Definition                                             |\n","|:---------------:|:------------------------------------------------------|\n","|Vandal           |1 if the edit was vandalism, 0 if not                  |\n","|Minor            |1 if the edit was marked as a minor edit, 0 if not     |    \n","|LoggedIn         |1 if the user made edit from Wiki account, 0 if not    |\n","|HTTP             |1 if edit contained web address, 0 if not              | \n","|NumWordsAdded    |Number of unique words added                           |\n","|NumWordsRemoved  |Number of unique words removed                         |\n","\n"]},{"cell_type":"markdown","metadata":{"id":"PRQ2bJhmvZmV"},"source":["## Decision Trees by Hand (Pencil and Paper / Textual if-then Visual)\n","\n","You are given a small sample of the total Wikipedia vandalism data as illustrated\n","below. The first two rows in the sample data contains two entry edits that were not vandalism, and last two edits  were. Given this data, design and illustrate two different binary decision trees (CART trees) that meet the following criteria:\n","\n","1. First CART tree: Classifies all data points with 100% accuracy.\n","2. Second CART tree: Uses a maximum of two splits, and classifies the data with $\\ge$ 75% accuracy."]},{"cell_type":"code","metadata":{"id":"UP9JV4MGku_B","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664804586167,"user_tz":240,"elapsed":16,"user":{"displayName":"Zhuolun Du","userId":"16686697190012944947"}},"outputId":"ee31463b-b15b-432d-c35f-b2ef70a89e09"},"source":["print(df.loc[list([0,1,2843,2844])])\n","\n","# Write your comment here.\n","\n","# -------------------\n","\n","\n","\n","\n","\n","\n","# -------------------"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["     Vandal Minor LoggedIn HTTP NumWordsAdded NumWordsRemoved\n","0         0     1        1    1            96               0\n","1         0     1        1    0             3               1\n","2843      1     1        1    0             1              12\n","2844      1     0        1    0            13               0\n"]}]},{"cell_type":"markdown","metadata":{"id":"uRZ5EcpcxbdU"},"source":["## Exploratory data analysis\n"]},{"cell_type":"markdown","metadata":{"id":"HBEZWBlIku_F"},"source":["### Exercise \n","\n","Prior to using CART and random forests to make predictions, we start with EDA to get a better feel for the Wikipedia dataset we are using.\n","1. Are there any non-numerical data values?"]},{"cell_type":"code","metadata":{"id":"TALkVINFku_H","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664804586374,"user_tz":240,"elapsed":220,"user":{"displayName":"Zhuolun Du","userId":"16686697190012944947"}},"outputId":"0fb5999f-5931-4a6d-b58a-9070967aa9b9"},"source":["# df_digit_indicator is calculated below to get you started. \n","df_digit_indicator = df.applymap(lambda x: x.isdigit())  \n","\n","# Write your code here.  \n","\n","# -------------------\n","\n","\n","(df_digit_indicator==False).sum()\n","\n","\n","# -------------------"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Vandal             2\n","Minor              1\n","LoggedIn           2\n","HTTP               1\n","NumWordsAdded      2\n","NumWordsRemoved    1\n","dtype: int64"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"TTaBzbxHku_J"},"source":["2. Are they properly stored as `NaN`, and if not, what are they stored as?"]},{"cell_type":"code","metadata":{"id":"bAJgO2X3ku_J","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664804586374,"user_tz":240,"elapsed":26,"user":{"displayName":"Zhuolun Du","userId":"16686697190012944947"}},"outputId":"f33694ec-8ecb-4490-c406-79a327a6ef2f"},"source":["# Write your code here.  \n","\n","# -------------------\n","\n","for col in df.columns:\n","  print(df[col][df_digit_indicator[col] == False].value_counts())\n","\n","# -------------------"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ERROR    2\n","Name: Vandal, dtype: int64\n","ERROR    1\n","Name: Minor, dtype: int64\n","ERROR    2\n","Name: LoggedIn, dtype: int64\n","ERROR    1\n","Name: HTTP, dtype: int64\n","ERROR    2\n","Name: NumWordsAdded, dtype: int64\n","ERROR    1\n","Name: NumWordsRemoved, dtype: int64\n"]}]},{"cell_type":"markdown","metadata":{"id":"tU1FUzaFku_L"},"source":["Now that we have identified some issues with the data, we should clean it and ensure all the entries are integer.\n","\n","3. Remove any invalid data points from `df`. Use this new `df` for the remainder of this lab."]},{"cell_type":"code","metadata":{"id":"-i7GG8A9ku_M"},"source":["# Write your code here.  \n","\n","# -------------------\n","\n","\n","df = df.replace('ERROR', np.nan)\n","df = df.dropna()\n","\n","# -------------------\n","\n","# Once the rows are deleted (or even before) it's important to ensure\n","# that all elements in this df are numeric. The code below will change\n","# strings to numeric values. \n","\n","df = df.apply(pd.to_numeric, errors='coerce')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xRQResYOku_P"},"source":["It will be easier to continue the EDA now that we have clean data in `df`.\n","\n","4. How many edits are considered? "]},{"cell_type":"code","metadata":{"id":"ad3eVJ2Aku_P","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664804586375,"user_tz":240,"elapsed":25,"user":{"displayName":"Zhuolun Du","userId":"16686697190012944947"}},"outputId":"57232068-220c-4e48-e19d-dafd9bce8720"},"source":["# Write your code here.  \n","\n","# -------------------\n","\n","\n","len(df)\n","\n","# -------------------"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3867"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"54efttQVku_U"},"source":["5. What percentage of the edits were deemed to be vandalism?"]},{"cell_type":"code","metadata":{"id":"Pd13DCubku_U","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664804586376,"user_tz":240,"elapsed":18,"user":{"displayName":"Zhuolun Du","userId":"16686697190012944947"}},"outputId":"aa57d042-b470-4f38-baf8-7558f53363c9"},"source":["# Write your code here.  \n","\n","# -------------------\n","\n","df.Vandal.sum()/len(df)\n","\n","\n","# -------------------"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.46754590121541245"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"6hW9xrQ4ku_W"},"source":["6. Of all the vandal edits, which one added the most words, and how many words were added?"]},{"cell_type":"code","metadata":{"id":"GK68Q5jjku_W","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664804586498,"user_tz":240,"elapsed":134,"user":{"displayName":"Zhuolun Du","userId":"16686697190012944947"}},"outputId":"88b982b3-e9bc-4135-af47-5a5e693d6ceb"},"source":["# Write your code here.  \n","\n","# -------------------\n","\n","\n","df.loc[df.NumWordsAdded.idxmax()]\n","\n","# -------------------"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Vandal               0\n","Minor                0\n","LoggedIn             1\n","HTTP                 0\n","NumWordsAdded      259\n","NumWordsRemoved      1\n","Name: 357, dtype: int64"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"yNhc-xrmku_Z"},"source":["7. Based on a cursory review of the dataset and domain intuition, which two feature variables (e.g., Minor, LoggedIn, HTTP, NumWordsAdded, and NumWordsRemoved) do you believe to be the most significant in predicting vandalism? Why? (No objective correct answer)."]},{"cell_type":"markdown","metadata":{"id":"VEyiV42Uku_Z"},"source":["___\n","__Question 7 Answer__:\n","\n","\n","___"]},{"cell_type":"markdown","metadata":{"id":"Zqd6JstLku_a"},"source":["## Splitting the Data\n","Randomly split data clean into a training set and test set, named data train and data test, respectively. We will place 70% of the data into the training set and the remainder in the test set. We will do this using the [`train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) function from `sklearn.model_selection`"]},{"cell_type":"code","metadata":{"id":"4DoYnecqku_c"},"source":["# from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(df.drop(columns='Vandal', axis=1), df['Vandal'], test_size=0.30, random_state=5)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tiTTmBmjku_e"},"source":["### Exercise\n","\n","Answer the following questions:\n","\n","1. How many points are in the training set?"]},{"cell_type":"code","metadata":{"id":"tEVQsiFVku_e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664804586499,"user_tz":240,"elapsed":13,"user":{"displayName":"Zhuolun Du","userId":"16686697190012944947"}},"outputId":"e66b6ca4-a6ae-4804-a702-d62f4639f911"},"source":["# Write your code here.  \n","\n","# -------------------\n","\n","len(X_train)\n","\n","# -------------------"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2706"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"nhFvTq3Oku_g"},"source":["2. How many confirmed vandalisms are in y_train?"]},{"cell_type":"code","metadata":{"id":"Nk0Pj2WAku_g","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664804586500,"user_tz":240,"elapsed":12,"user":{"displayName":"Zhuolun Du","userId":"16686697190012944947"}},"outputId":"072d1e69-5676-4d66-f4ea-1b6f327da8c3"},"source":["# Write your code here.  \n","\n","# -------------------\n","\n","y_train.sum()\n","\n","# -------------------"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1257"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"_-VaQhVoku_h"},"source":["# Using CART and RF with sklearn\n","\n","In the next section we will go over how the use the CART and RF classifiers in `sklearn`. The purpose of both of these methods is to classify target variables (e.g., Wikipedia edit is or is not vandalized), hence, these methods are more similar to logistic regression than they are to linear regression. Note, that random forest regression is also available in `sklearn`, which should be used instead of the classifiers if you're looking for a model to predict continuous values between positive and negative infinity (e.g., number of edits).\n","\n"]},{"cell_type":"markdown","metadata":{"id":"q62UtTfLNTGF"},"source":["## CART Model\n","\n","Use the [`DecisionTreeClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) function within `sklearn.tree`  to fit a CART model to the training set. There are several parameters that you can tune to prevent over fitting and to get better model accuracy. Recall that cross validation should be used to pick the best parameters for the model, but for simplicity we will neglect that step in this lab. One parameter you can set is `max_depth`, which controls the maximum number of levels in your trained model. In the example below we set the `max_depth` to three and visualize the resulting tree.  Figure 2 illustrates what a possible CART tree could look like for this application. Based on your produced tree, answer the following questions:"]},{"cell_type":"code","metadata":{"id":"p1axqvdVku_i","colab":{"base_uri":"https://localhost:8080/","height":635},"executionInfo":{"status":"ok","timestamp":1664804586957,"user_tz":240,"elapsed":461,"user":{"displayName":"Zhuolun Du","userId":"16686697190012944947"}},"outputId":"0c7b74fa-e0c7-4cb6-a0e4-12348f10cfe7"},"source":["# from sklearn.tree import DecisionTreeClassifier\n","# from sklearn.tree import export_graphviz\n","# from IPython.display import SVG\n","# from graphviz import Source\n","\n","# Train the CART model\n","cart_model = DecisionTreeClassifier(random_state=3,max_depth=3)\n","cart_model.fit(X_train, y_train)\n","train_score = cart_model.score(X_train, y_train)\n","test_score = cart_model.score(X_test, y_test)\n","\n","# Print out summary of model performance \n","print('The score of this model over training data is {:.3f} and {:.3f} over the testing data'.format(train_score, test_score))\n","\n","# Visualize the decision tree\n","cart_graph = Source(export_graphviz(cart_model,\n","                   feature_names = df.columns[1:],\n","                   rounded = True, proportion = False, \n","                   filled = True,\n","                   class_names=['0','1']))\n","SVG(cart_graph.pipe(format='svg'))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The score of this model over training data is 0.730 and 0.717 over the testing data\n"]},{"output_type":"execute_result","data":{"text/plain":["<IPython.core.display.SVG object>"],"image/svg+xml":"<svg height=\"433pt\" viewBox=\"0.00 0.00 1134.00 433.00\" width=\"1134pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 429)\">\n<title>Tree</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-429 1130,-429 1130,4 -4,4\" stroke=\"transparent\"/>\n<!-- 0 -->\n<g class=\"node\" id=\"node1\">\n<title>0</title>\n<path d=\"M586.5,-425C586.5,-425 461.5,-425 461.5,-425 455.5,-425 449.5,-419 449.5,-413 449.5,-413 449.5,-354 449.5,-354 449.5,-348 455.5,-342 461.5,-342 461.5,-342 586.5,-342 586.5,-342 592.5,-342 598.5,-348 598.5,-354 598.5,-354 598.5,-413 598.5,-413 598.5,-419 592.5,-425 586.5,-425\" fill=\"#fceee5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"524\" y=\"-409.8\">LoggedIn &lt;= 0.5</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"524\" y=\"-394.8\">gini = 0.497</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"524\" y=\"-379.8\">samples = 2706</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"524\" y=\"-364.8\">value = [1449, 1257]</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"524\" y=\"-349.8\">class = 0</text>\n</g>\n<!-- 1 -->\n<g class=\"node\" id=\"node2\">\n<title>1</title>\n<path d=\"M497,-306C497,-306 345,-306 345,-306 339,-306 333,-300 333,-294 333,-294 333,-235 333,-235 333,-229 339,-223 345,-223 345,-223 497,-223 497,-223 503,-223 509,-229 509,-235 509,-235 509,-294 509,-294 509,-300 503,-306 497,-306\" fill=\"#76bbed\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"421\" y=\"-290.8\">NumWordsAdded &lt;= 0.5</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"421\" y=\"-275.8\">gini = 0.36</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"421\" y=\"-260.8\">samples = 902</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"421\" y=\"-245.8\">value = [212, 690]</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"421\" y=\"-230.8\">class = 1</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g class=\"edge\" id=\"edge1\">\n<title>0-&gt;1</title>\n<path d=\"M487.9756,-341.8796C480.1802,-332.8733 471.8633,-323.2644 463.8356,-313.9897\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"466.3691,-311.5686 457.1782,-306.2981 461.0763,-316.1498 466.3691,-311.5686\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"455.381\" y=\"-327.5334\">True</text>\n</g>\n<!-- 8 -->\n<g class=\"node\" id=\"node9\">\n<title>8</title>\n<path d=\"M750,-306C750,-306 598,-306 598,-306 592,-306 586,-300 586,-294 586,-294 586,-235 586,-235 586,-229 592,-223 598,-223 598,-223 750,-223 750,-223 756,-223 762,-229 762,-235 762,-235 762,-294 762,-294 762,-300 756,-306 750,-306\" fill=\"#f1bb94\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"674\" y=\"-290.8\">NumWordsAdded &lt;= 0.5</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"674\" y=\"-275.8\">gini = 0.431</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"674\" y=\"-260.8\">samples = 1804</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"674\" y=\"-245.8\">value = [1237, 567]</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"674\" y=\"-230.8\">class = 0</text>\n</g>\n<!-- 0&#45;&gt;8 -->\n<g class=\"edge\" id=\"edge8\">\n<title>0-&gt;8</title>\n<path d=\"M576.4627,-341.8796C588.4521,-332.368 601.2887,-322.1843 613.5816,-312.432\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"615.9081,-315.054 621.5669,-306.0969 611.5575,-309.5701 615.9081,-315.054\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"618.7048\" y=\"-327.2326\">False</text>\n</g>\n<!-- 2 -->\n<g class=\"node\" id=\"node3\">\n<title>2</title>\n<path d=\"M286.5,-187C286.5,-187 113.5,-187 113.5,-187 107.5,-187 101.5,-181 101.5,-175 101.5,-175 101.5,-116 101.5,-116 101.5,-110 107.5,-104 113.5,-104 113.5,-104 286.5,-104 286.5,-104 292.5,-104 298.5,-110 298.5,-116 298.5,-116 298.5,-175 298.5,-175 298.5,-181 292.5,-187 286.5,-187\" fill=\"#fcefe6\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"200\" y=\"-171.8\">NumWordsRemoved &lt;= 2.5</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"200\" y=\"-156.8\">gini = 0.498</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"200\" y=\"-141.8\">samples = 300</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"200\" y=\"-126.8\">value = [160, 140]</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"200\" y=\"-111.8\">class = 0</text>\n</g>\n<!-- 1&#45;&gt;2 -->\n<g class=\"edge\" id=\"edge2\">\n<title>1-&gt;2</title>\n<path d=\"M343.7049,-222.8796C325.1152,-212.8697 305.1433,-202.1156 286.1773,-191.9031\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"287.7155,-188.7563 277.2514,-187.0969 284.3968,-194.9196 287.7155,-188.7563\" stroke=\"#000000\"/>\n</g>\n<!-- 5 -->\n<g class=\"node\" id=\"node6\">\n<title>5</title>\n<path d=\"M507.5,-187C507.5,-187 334.5,-187 334.5,-187 328.5,-187 322.5,-181 322.5,-175 322.5,-175 322.5,-116 322.5,-116 322.5,-110 328.5,-104 334.5,-104 334.5,-104 507.5,-104 507.5,-104 513.5,-104 519.5,-110 519.5,-116 519.5,-116 519.5,-175 519.5,-175 519.5,-181 513.5,-187 507.5,-187\" fill=\"#4ca6e7\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"421\" y=\"-171.8\">NumWordsRemoved &lt;= 0.5</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"421\" y=\"-156.8\">gini = 0.158</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"421\" y=\"-141.8\">samples = 602</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"421\" y=\"-126.8\">value = [52, 550]</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"421\" y=\"-111.8\">class = 1</text>\n</g>\n<!-- 1&#45;&gt;5 -->\n<g class=\"edge\" id=\"edge5\">\n<title>1-&gt;5</title>\n<path d=\"M421,-222.8796C421,-214.6838 421,-205.9891 421,-197.5013\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"424.5001,-197.298 421,-187.2981 417.5001,-197.2981 424.5001,-197.298\" stroke=\"#000000\"/>\n</g>\n<!-- 3 -->\n<g class=\"node\" id=\"node4\">\n<title>3</title>\n<path d=\"M112,-68C112,-68 12,-68 12,-68 6,-68 0,-62 0,-56 0,-56 0,-12 0,-12 0,-6 6,0 12,0 12,0 112,0 112,0 118,0 124,-6 124,-12 124,-12 124,-56 124,-56 124,-62 118,-68 112,-68\" fill=\"#f6d5bd\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"62\" y=\"-52.8\">gini = 0.48</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"62\" y=\"-37.8\">samples = 243</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"62\" y=\"-22.8\">value = [146, 97]</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"62\" y=\"-7.8\">class = 0</text>\n</g>\n<!-- 2&#45;&gt;3 -->\n<g class=\"edge\" id=\"edge3\">\n<title>2-&gt;3</title>\n<path d=\"M148.6139,-103.9815C136.7839,-94.4232 124.2136,-84.2668 112.4249,-74.7419\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"114.3851,-71.826 104.4071,-68.2637 109.9858,-77.2708 114.3851,-71.826\" stroke=\"#000000\"/>\n</g>\n<!-- 4 -->\n<g class=\"node\" id=\"node5\">\n<title>4</title>\n<path d=\"M246,-68C246,-68 154,-68 154,-68 148,-68 142,-62 142,-56 142,-56 142,-12 142,-12 142,-6 148,0 154,0 154,0 246,0 246,0 252,0 258,-6 258,-12 258,-12 258,-56 258,-56 258,-62 252,-68 246,-68\" fill=\"#79bded\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"200\" y=\"-52.8\">gini = 0.371</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"200\" y=\"-37.8\">samples = 57</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"200\" y=\"-22.8\">value = [14, 43]</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"200\" y=\"-7.8\">class = 1</text>\n</g>\n<!-- 2&#45;&gt;4 -->\n<g class=\"edge\" id=\"edge4\">\n<title>2-&gt;4</title>\n<path d=\"M200,-103.9815C200,-95.618 200,-86.7965 200,-78.3409\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"203.5001,-78.2636 200,-68.2637 196.5001,-78.2637 203.5001,-78.2636\" stroke=\"#000000\"/>\n</g>\n<!-- 6 -->\n<g class=\"node\" id=\"node7\">\n<title>6</title>\n<path d=\"M388,-68C388,-68 288,-68 288,-68 282,-68 276,-62 276,-56 276,-56 276,-12 276,-12 276,-6 282,0 288,0 288,0 388,0 388,0 394,0 400,-6 400,-12 400,-12 400,-56 400,-56 400,-62 394,-68 388,-68\" fill=\"#46a3e7\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"338\" y=\"-52.8\">gini = 0.113</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"338\" y=\"-37.8\">samples = 401</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"338\" y=\"-22.8\">value = [24, 377]</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"338\" y=\"-7.8\">class = 1</text>\n</g>\n<!-- 5&#45;&gt;6 -->\n<g class=\"edge\" id=\"edge6\">\n<title>5-&gt;6</title>\n<path d=\"M390.0939,-103.9815C383.3892,-94.9747 376.2892,-85.4367 369.5597,-76.3965\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"372.2845,-74.1953 363.5057,-68.2637 366.6694,-78.3752 372.2845,-74.1953\" stroke=\"#000000\"/>\n</g>\n<!-- 7 -->\n<g class=\"node\" id=\"node8\">\n<title>7</title>\n<path d=\"M530,-68C530,-68 430,-68 430,-68 424,-68 418,-62 418,-56 418,-56 418,-12 418,-12 418,-6 424,0 430,0 430,0 530,0 530,0 536,0 542,-6 542,-12 542,-12 542,-56 542,-56 542,-62 536,-68 530,-68\" fill=\"#59ade9\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"480\" y=\"-52.8\">gini = 0.24</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"480\" y=\"-37.8\">samples = 201</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"480\" y=\"-22.8\">value = [28, 173]</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"480\" y=\"-7.8\">class = 1</text>\n</g>\n<!-- 5&#45;&gt;7 -->\n<g class=\"edge\" id=\"edge7\">\n<title>5-&gt;7</title>\n<path d=\"M442.9694,-103.9815C447.5895,-95.2504 452.4736,-86.0202 457.126,-77.2281\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"460.2859,-78.7395 461.8694,-68.2637 454.0987,-75.4655 460.2859,-78.7395\" stroke=\"#000000\"/>\n</g>\n<!-- 9 -->\n<g class=\"node\" id=\"node10\">\n<title>9</title>\n<path d=\"M728,-187C728,-187 620,-187 620,-187 614,-187 608,-181 608,-175 608,-175 608,-116 608,-116 608,-110 614,-104 620,-104 620,-104 728,-104 728,-104 734,-104 740,-110 740,-116 740,-116 740,-175 740,-175 740,-181 734,-187 728,-187\" fill=\"#eca470\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"674\" y=\"-171.8\">Minor &lt;= 0.5</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"674\" y=\"-156.8\">gini = 0.34</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"674\" y=\"-141.8\">samples = 784</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"674\" y=\"-126.8\">value = [614, 170]</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"674\" y=\"-111.8\">class = 0</text>\n</g>\n<!-- 8&#45;&gt;9 -->\n<g class=\"edge\" id=\"edge9\">\n<title>8-&gt;9</title>\n<path d=\"M674,-222.8796C674,-214.6838 674,-205.9891 674,-197.5013\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"677.5001,-197.298 674,-187.2981 670.5001,-197.2981 677.5001,-197.298\" stroke=\"#000000\"/>\n</g>\n<!-- 12 -->\n<g class=\"node\" id=\"node13\">\n<title>12</title>\n<path d=\"M996.5,-187C996.5,-187 823.5,-187 823.5,-187 817.5,-187 811.5,-181 811.5,-175 811.5,-175 811.5,-116 811.5,-116 811.5,-110 817.5,-104 823.5,-104 823.5,-104 996.5,-104 996.5,-104 1002.5,-104 1008.5,-110 1008.5,-116 1008.5,-116 1008.5,-175 1008.5,-175 1008.5,-181 1002.5,-187 996.5,-187\" fill=\"#f6d1b7\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"910\" y=\"-171.8\">NumWordsRemoved &lt;= 0.5</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"910\" y=\"-156.8\">gini = 0.475</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"910\" y=\"-141.8\">samples = 1020</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"910\" y=\"-126.8\">value = [623, 397]</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"910\" y=\"-111.8\">class = 0</text>\n</g>\n<!-- 8&#45;&gt;12 -->\n<g class=\"edge\" id=\"edge12\">\n<title>8-&gt;12</title>\n<path d=\"M756.5413,-222.8796C776.5724,-212.7791 798.1064,-201.9209 818.5232,-191.626\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"820.152,-194.7245 827.5053,-187.0969 817.0003,-188.4742 820.152,-194.7245\" stroke=\"#000000\"/>\n</g>\n<!-- 10 -->\n<g class=\"node\" id=\"node11\">\n<title>10</title>\n<path d=\"M672,-68C672,-68 572,-68 572,-68 566,-68 560,-62 560,-56 560,-56 560,-12 560,-12 560,-6 566,0 572,0 572,0 672,0 672,0 678,0 684,-6 684,-12 684,-12 684,-56 684,-56 684,-62 678,-68 672,-68\" fill=\"#eeae80\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"622\" y=\"-52.8\">gini = 0.387</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"622\" y=\"-37.8\">samples = 373</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"622\" y=\"-22.8\">value = [275, 98]</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"622\" y=\"-7.8\">class = 0</text>\n</g>\n<!-- 9&#45;&gt;10 -->\n<g class=\"edge\" id=\"edge10\">\n<title>9-&gt;10</title>\n<path d=\"M654.6371,-103.9815C650.6081,-95.3423 646.3511,-86.2144 642.2897,-77.5059\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"645.3782,-75.8472 637.9795,-68.2637 639.0341,-78.8059 645.3782,-75.8472\" stroke=\"#000000\"/>\n</g>\n<!-- 11 -->\n<g class=\"node\" id=\"node12\">\n<title>11</title>\n<path d=\"M814,-68C814,-68 714,-68 714,-68 708,-68 702,-62 702,-56 702,-56 702,-12 702,-12 702,-6 708,0 714,0 714,0 814,0 814,0 820,0 826,-6 826,-12 826,-12 826,-56 826,-56 826,-62 820,-68 814,-68\" fill=\"#eb9c63\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"764\" y=\"-52.8\">gini = 0.289</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"764\" y=\"-37.8\">samples = 411</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"764\" y=\"-22.8\">value = [339, 72]</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"764\" y=\"-7.8\">class = 0</text>\n</g>\n<!-- 9&#45;&gt;11 -->\n<g class=\"edge\" id=\"edge11\">\n<title>9-&gt;11</title>\n<path d=\"M707.5127,-103.9815C714.857,-94.8828 722.6388,-85.242 730.0019,-76.1199\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"732.7857,-78.2434 736.3432,-68.2637 727.3388,-73.8467 732.7857,-78.2434\" stroke=\"#000000\"/>\n</g>\n<!-- 13 -->\n<g class=\"node\" id=\"node14\">\n<title>13</title>\n<path d=\"M964,-68C964,-68 856,-68 856,-68 850,-68 844,-62 844,-56 844,-56 844,-12 844,-12 844,-6 850,0 856,0 856,0 964,0 964,0 970,0 976,-6 976,-12 976,-12 976,-56 976,-56 976,-62 970,-68 964,-68\" fill=\"#fefbf8\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"910\" y=\"-52.8\">gini = 0.5</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"910\" y=\"-37.8\">samples = 466</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"910\" y=\"-22.8\">value = [237, 229]</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"910\" y=\"-7.8\">class = 0</text>\n</g>\n<!-- 12&#45;&gt;13 -->\n<g class=\"edge\" id=\"edge13\">\n<title>12-&gt;13</title>\n<path d=\"M910,-103.9815C910,-95.618 910,-86.7965 910,-78.3409\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"913.5001,-78.2636 910,-68.2637 906.5001,-78.2637 913.5001,-78.2636\" stroke=\"#000000\"/>\n</g>\n<!-- 14 -->\n<g class=\"node\" id=\"node15\">\n<title>14</title>\n<path d=\"M1114,-68C1114,-68 1006,-68 1006,-68 1000,-68 994,-62 994,-56 994,-56 994,-12 994,-12 994,-6 1000,0 1006,0 1006,0 1114,0 1114,0 1120,0 1126,-6 1126,-12 1126,-12 1126,-56 1126,-56 1126,-62 1120,-68 1114,-68\" fill=\"#f0b88f\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1060\" y=\"-52.8\">gini = 0.423</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1060\" y=\"-37.8\">samples = 554</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1060\" y=\"-22.8\">value = [386, 168]</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1060\" y=\"-7.8\">class = 0</text>\n</g>\n<!-- 12&#45;&gt;14 -->\n<g class=\"edge\" id=\"edge14\">\n<title>12-&gt;14</title>\n<path d=\"M965.8545,-103.9815C978.8368,-94.3313 992.6394,-84.0714 1005.5597,-74.4673\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"1007.9678,-77.0384 1013.9054,-68.2637 1003.7917,-71.4204 1007.9678,-77.0384\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"-1gsRzdIku_j"},"source":["### Exercise \n","\n","Based on the tree, answer the following questions:\n","1. How many nodes are in the tree? You can count on the image, or use the method `tree_.node_count` on your model."]},{"cell_type":"code","metadata":{"id":"bMHU6LP6ku_j","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664804586958,"user_tz":240,"elapsed":6,"user":{"displayName":"Zhuolun Du","userId":"16686697190012944947"}},"outputId":"4fcbfeac-b7d9-4b31-ecf8-c8c15273347c"},"source":["# Write your code here.  \n","\n","# -------------------\n","\n","cart_model.tree_.node_count\n","\n","# -------------------"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["15"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"AD484Raznde4"},"source":["___\n","__Question 1 Answer__:\n","\n","\n","___"]},{"cell_type":"markdown","metadata":{"id":"t2a9GcIkku_l"},"source":["2. Which feature variable is split at the root node?"]},{"cell_type":"markdown","metadata":{"id":"LmVJXKg1ku_l"},"source":["___\n","__Question 2 Answer__:\n","\n","\n","___"]},{"cell_type":"markdown","metadata":{"id":"k9H51saIku_l"},"source":["3. Apply the `feature_importances` method on your model, which of the feature variables are important? Note, these values returned by `feature_importances` are also known as the Gini measure of the variable. The variables with the larger importance or Gini measures are the ones that we split on at the top of the tree and are considered more important. "]},{"cell_type":"code","metadata":{"id":"CXIuMLv1ku_l","colab":{"base_uri":"https://localhost:8080/","height":80},"executionInfo":{"status":"ok","timestamp":1664770592306,"user_tz":240,"elapsed":111,"user":{"displayName":"Zhuolun Du","userId":"16686697190012944947"}},"outputId":"8192b593-33c1-41a0-b69a-cb34fef01f26"},"source":["# Write your code here.\n","\n","# -------------------\n","\n","pd.DataFrame(cart_model.feature_importances_, index=X_train.columns).T\n","\n","# -------------------"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      Minor  LoggedIn  HTTP  NumWordsAdded  NumWordsRemoved\n","0  0.007789   0.63467   0.0       0.276306         0.081235"],"text/html":["\n","  <div id=\"df-c2989d8c-d237-4d3f-91d0-d91cc6053624\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Minor</th>\n","      <th>LoggedIn</th>\n","      <th>HTTP</th>\n","      <th>NumWordsAdded</th>\n","      <th>NumWordsRemoved</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.007789</td>\n","      <td>0.63467</td>\n","      <td>0.0</td>\n","      <td>0.276306</td>\n","      <td>0.081235</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c2989d8c-d237-4d3f-91d0-d91cc6053624')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c2989d8c-d237-4d3f-91d0-d91cc6053624 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c2989d8c-d237-4d3f-91d0-d91cc6053624');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":21}]},{"cell_type":"markdown","metadata":{"id":"UR8Pyncbku_n"},"source":["4. Assess the accuracy of your model on the testing set. What % of predictions are correct?"]},{"cell_type":"code","metadata":{"id":"aqYi7JADku_n","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664804609459,"user_tz":240,"elapsed":131,"user":{"displayName":"Zhuolun Du","userId":"16686697190012944947"}},"outputId":"27bd5bb6-86ec-4ed3-88a4-651865b39d26"},"source":["# Write your code here.  \n","\n","# -------------------\n","\n","np.mean(cart_model.predict(X_test) == y_test)\n","\n","\n","# -------------------"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.7166236003445305"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["cart_model.score(X_test, y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h7iZv9o_FmUp","executionInfo":{"status":"ok","timestamp":1664804668400,"user_tz":240,"elapsed":110,"user":{"displayName":"Zhuolun Du","userId":"16686697190012944947"}},"outputId":"a0d9eb14-f48b-44cc-9957-374fef6147ef"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.7166236003445305"]},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"Rc6zva3pku_o"},"source":["5. Constrain the `max_depth` to 10. What is the new accuracy of the model on the training and testing set? Do you think this model has overfit the data?"]},{"cell_type":"code","metadata":{"id":"AsugiUCiku_o","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664804757354,"user_tz":240,"elapsed":96,"user":{"displayName":"Zhuolun Du","userId":"16686697190012944947"}},"outputId":"68726e45-ab3d-4c7e-8028-9cd4e0c6e295"},"source":["# Write your code here.\n","\n","# -------------------\n","\n","cart_model = DecisionTreeClassifier(random_state=0,max_depth=10)\n","cart_model.fit(X_train, y_train)\n","mdlAccTrain = np.mean((cart_model.predict(X_train) == y_train))\n","mdlAccTest = np.mean((cart_model.predict(X_test) == y_test))\n","\n","print('The accuracy on the: \\n\\t training data is {}'.format(round(mdlAccTrain,3)))\n","print('\\t testing data is {}'.format(round(mdlAccTest,3)))\n","\n","# -------------------"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The accuracy on the: \n","\t training data is 0.773\n","\t testing data is 0.721\n"]}]},{"cell_type":"markdown","metadata":{"id":"GLKXsUUzoKnc"},"source":["___\n","__Question 5 Answer__:\n","\n","\n","___"]},{"cell_type":"markdown","metadata":{"id":"iaD_4Kn9tch4"},"source":["Throughout this lab we will fit and \"score\" models several time, so to be efficient (and to follow good coding practice!) we should make a function that fits and scores a model. For future labs and projects you should try to introduce functions where possible. "]},{"cell_type":"code","metadata":{"id":"PccQnTFytdEA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664804801671,"user_tz":240,"elapsed":129,"user":{"displayName":"Zhuolun Du","userId":"16686697190012944947"}},"outputId":"d1e2e82c-57f7-4da7-f6ed-9ba64e422ea7"},"source":["def fit_and_score_model(mdl, X_train, X_test, y_train, y_test, random_state=0):\n","    \"\"\"\n","    This function will fit and score the input mdl to the X_train and y_train \n","    data, and score the mdl on y_train and y_test. To ensure results are \n","    reproducible we can also set a random state.\n","    \"\"\"\n","  \n","    # Fit an arbitrary model\n","    mdl.fit(X_train, y_train)\n","    \n","    # Calculate the score of the model on training and testing data\n","    train_score = mdl.score(X_train, y_train)\n","    test_score = mdl.score(X_test, y_test)\n","  \n","    # Print scores to terminal\n","    print('the accuracy on the: \\n\\t training data is {}'.format(round(train_score,3)))\n","    print('\\t testing data is {}'.format(round(test_score, 3)))\n","    \n","    return train_score, test_score\n","  \n","# As an example, you can now call the function fit_and_score_model\n","cart_model = DecisionTreeClassifier(random_state=0,max_depth=10)\n","train_score, test_score = fit_and_score_model(cart_model, X_train, X_test, y_train, y_test)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["the accuracy on the: \n","\t training data is 0.773\n","\t testing data is 0.721\n"]}]},{"cell_type":"markdown","metadata":{"id":"i75YD2GOku_p"},"source":["## Random Forest Model\n","\n","As was dicussed in the background section, individual CART trees can tend to overfit the data. To reduce this effect, and improve subsequent model performance, we can combine the results of many decision trees in a random forest.\n","\n","Use the [`RandomForestClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) function from `sklearn.ensemble` to create a random forest model. This function combines classification trees by default (as required) and creates a bootstrapped sample of the full dataset.\n","\n","Set the size of each bootstrapped sample to *0.2*, which corresponds to one fifth the size of the training data by using the `max_samples` parameter. We also set the `bootstrap` parameter to *True*. Note: We didn't have to make the bootstrapped sample size equal to one fifth of the training dataset. This is a parameter that can be tuned, but we will not focus on that for this lab. (It is possible to have the bootstrapped size = full training data set size as well, since our sampling with replacement will still create different datasets used to create each tree).\n","\n","Include 50 individual CART trees in your random forest model using the `n_estimators` parameter. Set the `random_state` attribute to 0 which will allow us to all produce the same results.\n","\n","Experiment with `max_depth` parameter of `RandomForestClassifier` $\\in$ {2, 3, 4, 5, 6, 7} and measure the accuracy on the testing set. \n","\n","Note, we do not need to explicitly specify the proportion of the features we will use for each CART tree in the random forest, because the default setting for `RandomForestClassifier` is $\\sqrt{n\\_features}$"]},{"cell_type":"code","metadata":{"id":"ZJ3bimhoku_p","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664805615518,"user_tz":240,"elapsed":777,"user":{"displayName":"Zhuolun Du","userId":"16686697190012944947"}},"outputId":"55dcaf0d-84d6-4925-e634-41234d000c32"},"source":["# from sklearn.ensemble import RandomForestClassifier\n","\n","depths = [2, 3, 4, 5, 6, 7]\n","accuracy = pd.Series(index=depths, dtype=float)\n","\n","# Write your code here. \n","\n","# -------------------\n","\n","for max_depth in depths:\n","\n","    model = RandomForestClassifier(\n","        random_state = 0, \n","        max_depth = max_depth,\n","        n_estimators = 50,\n","        max_samples = 0.2\n","    )\n","    \n","    print('For {} max_depth '.format(max_depth), end='')\n","    train_score, test_score = fit_and_score_model(model, X_train, X_test, y_train, y_test)\n","    \n","    # Save model performance to dataframe\n","    accuracy.loc[max_depth] = test_score\n","\n","# -------------------"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["For 2 max_depth the accuracy on the: \n","\t training data is 0.712\n","\t testing data is 0.716\n","For 3 max_depth the accuracy on the: \n","\t training data is 0.738\n","\t testing data is 0.724\n","For 4 max_depth the accuracy on the: \n","\t training data is 0.74\n","\t testing data is 0.724\n","For 5 max_depth the accuracy on the: \n","\t training data is 0.752\n","\t testing data is 0.731\n","For 6 max_depth the accuracy on the: \n","\t training data is 0.753\n","\t testing data is 0.73\n","For 7 max_depth the accuracy on the: \n","\t training data is 0.755\n","\t testing data is 0.73\n"]}]},{"cell_type":"markdown","metadata":{"id":"pJaBGSYYku_q"},"source":["### Exercise\n","\n","Based on your random forest model, answer the following questions:\n","1. What was the `max_depth` in your best performing random forest?"]},{"cell_type":"code","metadata":{"id":"6BTIlhZ71T6e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664805641742,"user_tz":240,"elapsed":166,"user":{"displayName":"Zhuolun Du","userId":"16686697190012944947"}},"outputId":"6f716b73-72d2-4af2-fcf4-27b37dfe6052"},"source":["# Write your code here.\n","# -------------------\n","\n","\n","accuracy.idxmax()\n","\n","# -------------------"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["5"]},"metadata":{},"execution_count":20}]},{"cell_type":"markdown","metadata":{"id":"a0wmufaLku_r"},"source":["2. What is the accuracy/score of your best performing random forest?"]},{"cell_type":"code","metadata":{"id":"c34TGZCAku_r","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664805649982,"user_tz":240,"elapsed":88,"user":{"displayName":"Zhuolun Du","userId":"16686697190012944947"}},"outputId":"852b9829-9f96-4309-b083-7746bf1dd06e"},"source":["# Write your code here.\n","# -------------------\n","\n","\n","accuracy.max()\n","\n","# -------------------"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.7312661498708011"]},"metadata":{},"execution_count":21}]},{"cell_type":"markdown","metadata":{"id":"vmClYcIbku_s"},"source":["3. Is this a fair way to choose model parameters? Why or why not?"]},{"cell_type":"markdown","metadata":{"id":"fitc5H7txA7w"},"source":["___\n","__Question 3 Answer__:\n","\n","\n","___\n","\n"]},{"cell_type":"markdown","metadata":{"id":"r0S8skHNku_t"},"source":["4. Does increasing the `max_depth` increase or decrease overfitting?"]},{"cell_type":"markdown","metadata":{"id":"yVXQwo_SxGor"},"source":["___\n","__Question 4 Answer__:\n","\n","\n","\n","\n","___"]},{"cell_type":"markdown","metadata":{"id":"-OMesF84ku_u"},"source":["5. Does your best random forest model out perform your CART model?"]},{"cell_type":"markdown","metadata":{"id":"64Np5Mv_xH-l"},"source":["___\n","__Question 5 Answer__:\n","\n","\n","\n","___"]},{"cell_type":"markdown","metadata":{"id":"dNSEBC4olk1T"},"source":["# Cross-validation"]},{"cell_type":"markdown","metadata":{"id":"Qt-nQmbbrH03"},"source":["Now that we can code the CART (`DecisionTreeClassifier`) and random forests (`RandomForestClassifier`) it's time to learn about how to adjust parameters to improve model performance. In this section, we'll focus exclusively on the RF, but the methods generalize to other models (e.g., linear regression, CART, deep learning). In the Random Forest section, we chose an appropriate value for the `max_depth` parameter by evaluating the model on the test data (i.e., `X_test` and `y_test`). However, this is cheating because we are using the test set to make modeling decisions. In the real world, we should deploy a model that generalizes well to unseen data. If we use the test set to help tune our model, then the model has \"seen\" the test data so we can no longer offer guarantees about how well it will generalize to unseen data.\n","\n","To address the issue, we will apply a procedure called cross-validation to select model parameters using only the training set. There are various ways to perform cross-validation. We will focus on a popular method called *m*-fold cross-validation where *m* is a parameter representing the number of groups that the training set is split into. Specifically, given a model, the general procedure is summarized below.\n","\n","1.   Randomly shuffle the training set.\n","2.   Partition the training set into *m* groups of equal size.\n","3.   For each group:\n","    \n",">a. Take the group as a hold-out subset for model evaluation.\n","\n",">b. Take the remaining groups as the training data.\n","\n",">c. Fit the model on the training data.\n","    \n",">d. Evaluate the model on the hold-out set using the selected performance measure.\n","\n","4. Summarize the measure of performance across the *m* (e.g. average the *m* validation results).\n","\n","In this procedure, each data point in the training set is in the hold-out set exactly once and is used to train the model *m-1* times. The aggregated performance measure calculated in step 4 provides a less biased estimate of the model performance on unseen data, compared to a single train-test split, because it considers the variability across different splits. We thus use this aggregated measure to select model parameters. Once the \"best\" parameters are selected, we can re-train the model using the entire training set and the selected parameter, and then evaluate the final model using the test set. Important note that the purpose of this evaluation is to provide a more accurate estimate of model performance on unseen data. We can not go back to change the selected model parameters.\n","\n","As you may notice, *m* is another parameter that we have to choose. For simplicity, we set *m = 5* in this lab. But any value of *m* can be selected in practice.\n","\n","Now, let's use cross-validation to choose the `max_depth` parameter in our RF model. We will use `cross_validate` from `sklearn` to make the appropriate data splits, and we'll take the model with the highest average score."]},{"cell_type":"code","metadata":{"id":"XAm6DP_MlkT9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664805723010,"user_tz":240,"elapsed":12071,"user":{"displayName":"Zhuolun Du","userId":"16686697190012944947"}},"outputId":"9294eaa3-ff03-4a8a-d120-b5e75ae7a092"},"source":["# from sklearn.model_selection import cross_validate\n","\n","# Initialize cross validation score DataFrame\n","depth_lb = 1\n","depth_ub = 21\n","cv_scores = pd.Series(index=np.arange(depth_lb, depth_ub), dtype=float)\n","\n","for max_depth in range(depth_lb, depth_ub):\n","  \n","  # Initialize the model\n","  rf_cv1_model = RandomForestClassifier(random_state = 0, max_depth = max_depth,\n","                          n_estimators = 50, max_samples=0.2)\n","\n","  # Run cross validation to get measure of out-of-sample error\n","  example_cv_results = cross_validate(rf_cv1_model, X_train, y_train, cv=5)\n","  \n","  # Record the average out-of-sample error\n","  cv_scores.loc[max_depth] = example_cv_results['test_score'].mean()\n","\n","print(\"Completed\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Completed\n"]}]},{"cell_type":"markdown","metadata":{"id":"dIbAvj35qCQa"},"source":["### Exercise\n","\n","Based on this result, answer the following questions:\n","\n","1. Plot the `cv_scores` values. Which `max_depth` would you choose for this model? How does it compare to the `max_depth` you would have picked without cross validation (when we \"cheated\")? "]},{"cell_type":"code","metadata":{"id":"FRh8yy73QV7x","colab":{"base_uri":"https://localhost:8080/","height":296},"executionInfo":{"status":"ok","timestamp":1664805808034,"user_tz":240,"elapsed":616,"user":{"displayName":"Zhuolun Du","userId":"16686697190012944947"}},"outputId":"c8e28b55-0db2-4f4e-e957-571b05291fde"},"source":["# Write your code here.\n","\n","# -------------------\n","sns.scatterplot(x=cv_scores.index, y=cv_scores.values)\n","plt.xlabel('Max Depth')\n","plt.ylabel('Score')\n","\n","cv_scores.idxmax()\n","\n","# -------------------"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["6"]},"metadata":{},"execution_count":23},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"di6LdQytap6F"},"source":["2. Based on the cross validations, what value of the `max_depth` parameter would you use to train a RF on this data set? "]},{"cell_type":"markdown","metadata":{"id":"uq-ROXMs_4cO"},"source":["___\n","__Question 2 Answer__:\n","\n","\n","___"]},{"cell_type":"markdown","metadata":{"id":"RmelC9af_57D"},"source":["3. Write code to perform your own manual cross validation. Do not use functions from `sklearn` other than `RandomForestClassifier`. To help, we provide an array `random_indices` that is the length of the training set but contains the row numbers in a randomized order. We also provide `integer_splits`, which is the breakpoints in the total number of rows that will allow 5-equal sized folds. You can refer to the procedure descrived above to structure your code. \n","\n","  For each `max_depth` value, you need to fit the data and evaluate it on each fold (this results in fitting the model 105 = 21 x 5 times). Important note, across different parameter values, the folds should be consistent.\n"]},{"cell_type":"code","source":["depths = list(range(1, 22)) # candidate values of \"max_depth\"\n","cv_scores = pd.Series(index=depths, dtype=float)  # use to store the model performance on each hold-out set.\n","\n","m = 5  # number of folds\n","training_set_size = len(y_train) # get the size of the training set\n","np.random.seed(0) # manually set the random seed (np.random.permutation below doesn't accept a random_state parameter)\n","random_indices = np.random.permutation(training_set_size) # create an array with the row numbers in a randomized order\n","fractional_splits = np.concatenate(([0], np.repeat(1/m, m).cumsum())) # create the fractional splits that divide the training set into 5 folds\n","integer_splits = np.array(np.floor(fractional_splits * training_set_size),dtype=int) # determine the row numbers / breakpoints that divide the training set into 5 folds\n","\n","# Write your code here. \n","\n","# -------------------\n","\n","for depth in depths:\n","  total_score = pd.Series(index=range(m))\n","  for i in range(m):\n","    v_index = random_indices[integer_splits[i]:integer_splits[i+1]]\n","    t_index = np.delete(random_indices, range(*integer_splits[i:i+2]))\n","    \n","    model = RandomForestClassifier(random_state = 0,\n","                                   max_depth = depth,\n","                                   n_estimators = 50,\n","                                   max_samples = 0.2)\n","    \n","    _, v_score = fit_and_score_model(\n","        model, \n","        X_train.iloc[t_index],\n","        X_train.iloc[v_index],\n","        y_train.iloc[t_index],\n","        y_train.iloc[v_index]\n","    )\n","    # Record the average out-of-sample error\n","    total_score.loc[i] = v_score\n","\n","  cv_scores.loc[depth] = total_score.mean()\n","\n","sns.scatterplot(x=cv_scores.index, y=cv_scores.values)\n","plt.xlabel('Max Depth')\n","plt.ylabel('Score')\n","\n","# -------------------"],"metadata":{"id":"DQuYEjWUaL4c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4Lp7X_6M_8J-"},"source":["4. Compare your RF model to a logistic regression with cross validation (i.e. `LogisticRegressionCV` from `sklearn.linear_model`). Use penalty l2, solver lbfgs and cv with 5 folds. What model is more accurate? "]},{"cell_type":"code","metadata":{"id":"HhlYuflch-bR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664807233488,"user_tz":240,"elapsed":5254,"user":{"displayName":"Zhuolun Du","userId":"16686697190012944947"}},"outputId":"059a4beb-27b0-4b2c-a453-0acfb009d12c"},"source":["# from sklearn.linear_model import LogisticRegressionCV\n","\n","# Write your code here.  \n","\n","# -------------------\n","\n","logregcv = LogisticRegressionCV(penalty='l2', solver='lbfgs', cv=5)\n","train_score, test_score = fit_and_score_model(logregcv, X_train, X_test, y_train, y_test)\n","\n","\n","\n","# -------------------"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["the accuracy on the: \n","\t training data is 0.717\n","\t testing data is 0.717\n"]}]},{"cell_type":"markdown","metadata":{"id":"qVF9b7CE26Hj"},"source":["___\n","__Question 4 Answer__:\n","\n","\n","\n","___"]},{"cell_type":"markdown","metadata":{"id":"0MqoqOzNku_v"},"source":["# Reflection\n","As this is an _Analytics in Action_ course, we should think about how valuable our models are with respect to real-world applications. Position yourself as an employee of Wikipedia, and answer the following questions\n","\n","1. Are your models useful to your company in detecting page vandalism? Why or why not?"]},{"cell_type":"markdown","metadata":{"id":"1J9nrGSAku_v"},"source":["___\n","__Question 1 Answer__:\n","\n","\n","\n","___"]},{"cell_type":"markdown","metadata":{"id":"y9zPf1h8ku_v"},"source":["2. What other information about the edits (i.e. feature variables not in the dataset) could be useful to detect vandalism?"]},{"cell_type":"markdown","metadata":{"id":"7cpL4Crfku_v"},"source":["___\n","__Question 2 Answer__:\n","\n","\n","\n","\n","___"]},{"cell_type":"markdown","metadata":{"id":"-3IALNtNku_v"},"source":["3. The findings in this work centre around the Language Wiki page. Do you think these methods would extend to other pages too?"]},{"cell_type":"markdown","metadata":{"id":"hnhOl4dOku_w"},"source":["___\n","__Question 3 Answer__:\n","\n","\n","\n","___"]},{"cell_type":"code","source":[],"metadata":{"id":"DsTexFO4pdE2"},"execution_count":null,"outputs":[]}]}